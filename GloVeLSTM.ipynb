{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/haoran/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import string\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "from keras.preprocessing import sequence, text\n",
    "from keras.layers import  Input, Dense, Flatten, Add, LSTM, GlobalAveragePooling1D,SpatialDropout1D, Bidirectional,\\\n",
    "    BatchNormalization, Concatenate, Dropout, Activation, Input, Embedding, Conv1D, MaxPooling1D, \\\n",
    "    GlobalMaxPooling1D\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Model, load_model\n",
    "import tensorflow as tf\n",
    "from keras import regularizers\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, TensorBoard, Callback\n",
    "import keras.backend as K\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "class ROCCallBack(Callback):\n",
    "    def __init__(self,validation_data):\n",
    "        super().__init__()\n",
    "        self.x_val = validation_data[0]\n",
    "        self.y_val = validation_data[1]\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        y_pred_val = self.model.predict(self.x_val)\n",
    "        print('\\nroc-auc_val: %s' % (str(round(roc_auc_score(self.y_val, y_pred_val),4))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def flatten(x):\n",
    "    if isinstance(x, (np.ndarray, list, tuple, pd.Series)):\n",
    "        lst = []\n",
    "        for i in x:\n",
    "            lst += flatten(i)\n",
    "        return lst\n",
    "    else:\n",
    "        return [x]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('data/train.csv')\n",
    "test = pd.read_csv('data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output_names = ['toxic','severe_toxic','obscene','threat','insult','identity_hate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tok=text.Tokenizer(filters = '!\"#$%&()*+,-./:;<=>?@[\\\\]^_\\'`{|}~\\t\\n', lower=True)\n",
    "tok.fit_on_texts(np.concatenate((train.comment_text.values, test.comment_text.values)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load GloVe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f = open('data/glove.42B.300d.txt', 'r', encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_unique_tokens = tok.word_index.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embeddings = {}\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    # Whole GloVe embeddings doesn't fit in my GPU memory, so only take words which appear in data for now. \n",
    "    # Can always swap weights for embedding layer after model training\n",
    "    if word in all_unique_tokens:\n",
    "        coefs = np.array(values[1:], dtype = 'float32')\n",
    "        embeddings[word] = coefs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in list(tok.word_index.keys()):\n",
    "    if i not in embeddings.keys():\n",
    "        del tok.word_index[i]\n",
    "for counter, i in enumerate(tok.word_index.keys()):\n",
    "    tok.word_index[i] = counter+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "idx2word = {b:a for a,b in tok.word_index.items()}\n",
    "idx2word[0] = '<UNK>'\n",
    "word2idx = defaultdict(lambda x: '<UNK>', tok.word_index)\n",
    "embeddings['<UNK>'] = np.zeros((300,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train['toks'] = tok.texts_to_sequences(train.comment_text.values)\n",
    "test['toks'] = tok.texts_to_sequences(test.comment_text.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vocab_size = len(embeddings)\n",
    "max_len = 300\n",
    "n_factors = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_emb():\n",
    "    emb = np.zeros((vocab_size+1,n_factors), dtype = 'float32')\n",
    "    for i in range(0, vocab_size):\n",
    "        word = idx2word[i]\n",
    "        emb[i,:] = embeddings[word] #each row is a word\n",
    "    return emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "emb = create_emb()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(190324, 300)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train val  split\n",
    "np.random.seed(10)\n",
    "indexTrain = np.random.choice(range(train.shape[0]), size = int(0.9*train.shape[0]), replace = False)\n",
    "indexVal = list(set(range(train.shape[0])) - set(indexTrain))\n",
    "traindf = train.loc[indexTrain]\n",
    "valdf = train.loc[indexVal]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataInputTrain=sequence.pad_sequences(traindf.toks,maxlen=max_len)\n",
    "dataInputVal=sequence.pad_sequences(valdf.toks,maxlen=max_len)\n",
    "dataInputTest=sequence.pad_sequences(test.toks,maxlen=max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> <UNK> reviewing edits hi it appears you approved this edit which was the change of a cited number to a different number without changing the citation that edit is not an improvement to the article as it adds false or misleading information to the text it cites a source to a number where the source does not support that number and it should not have been approved please be careful when approving these types of edits best'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join([idx2word[i] for i in dataInputTrain[10,:]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sequence_input = Input(shape=(max_len, ))\n",
    "x = Embedding(vocab_size+1, n_factors, input_length=max_len, weights=[emb],trainable = False)(sequence_input)\n",
    "x = Bidirectional(LSTM(128, return_sequences=True,dropout=0.15,recurrent_dropout=0.15))(x)\n",
    "x = Conv1D(128, kernel_size = 5, padding = \"valid\", kernel_initializer = \"glorot_uniform\")(x)\n",
    "avg_pool = GlobalAveragePooling1D()(x)\n",
    "max_pool = GlobalMaxPooling1D()(x)\n",
    "x = Concatenate()([avg_pool, max_pool])\n",
    "x = BatchNormalization(axis = -1)(x)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Dense(256, activation = 'relu')(x)\n",
    "x = BatchNormalization(axis = -1)(x)\n",
    "x = Dropout(0.5)(x)\n",
    "preds = Dense(6, activation=\"sigmoid\")(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Model(sequence_input, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 300)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 300, 300)     57097200    input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional) (None, 300, 256)     439296      embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 296, 128)     163968      bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_1 (Glo (None, 128)          0           conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_1 (GlobalM (None, 128)          0           conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 256)          0           global_average_pooling1d_1[0][0] \n",
      "                                                                 global_max_pooling1d_1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 256)          1024        concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 256)          0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 256)          65792       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 256)          1024        dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 256)          0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 6)            1542        dropout_2[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 57,769,846\n",
      "Trainable params: 671,622\n",
      "Non-trainable params: 57,098,224\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy',optimizer=Adam(lr=1e-3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "earlyStopping = EarlyStopping(monitor='val_loss', patience=5, verbose=0, mode='min')\n",
    "mcp_save = ModelCheckpoint('weights/lstm_mdl', save_best_only=True, monitor='val_loss', mode='min')\n",
    "reduce_lr_loss = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=3, verbose=1, epsilon=1e-4, mode='min')\n",
    "tensor_board = TensorBoard(log_dir='./logs/run3', write_graph = False,)\n",
    "roc_callback = ROCCallBack(validation_data = [dataInputVal, valdf[output_names].values])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 143613 samples, validate on 15958 samples\n",
      "Epoch 1/200\n",
      "143552/143613 [============================>.] - ETA: 0s - loss: 0.1018\n",
      "roc-auc_val: 0.977\n",
      "143613/143613 [==============================] - 1769s 12ms/step - loss: 0.1018 - val_loss: 0.0501\n",
      "Epoch 2/200\n",
      "143552/143613 [============================>.] - ETA: 0s - loss: 0.0502\n",
      "roc-auc_val: 0.9826\n",
      "143613/143613 [==============================] - 1732s 12ms/step - loss: 0.0502 - val_loss: 0.0435\n",
      "Epoch 3/200\n",
      "143552/143613 [============================>.] - ETA: 0s - loss: 0.0455\n",
      "roc-auc_val: 0.9847\n",
      "143613/143613 [==============================] - 1732s 12ms/step - loss: 0.0455 - val_loss: 0.0420\n",
      "Epoch 4/200\n",
      "143552/143613 [============================>.] - ETA: 0s - loss: 0.0424\n",
      "roc-auc_val: 0.9867\n",
      "143613/143613 [==============================] - 1731s 12ms/step - loss: 0.0424 - val_loss: 0.0424\n",
      "Epoch 5/200\n",
      "143552/143613 [============================>.] - ETA: 0s - loss: 0.0401\n",
      "roc-auc_val: 0.988\n",
      "143613/143613 [==============================] - 1731s 12ms/step - loss: 0.0401 - val_loss: 0.0410\n",
      "Epoch 6/200\n",
      "143552/143613 [============================>.] - ETA: 0s - loss: 0.0378\n",
      "roc-auc_val: 0.9883\n",
      "143613/143613 [==============================] - 1731s 12ms/step - loss: 0.0378 - val_loss: 0.0400\n",
      "Epoch 7/200\n",
      "143552/143613 [============================>.] - ETA: 0s - loss: 0.0355\n",
      "roc-auc_val: 0.988\n",
      "143613/143613 [==============================] - 1731s 12ms/step - loss: 0.0355 - val_loss: 0.0408\n",
      "Epoch 8/200\n",
      "143552/143613 [============================>.] - ETA: 0s - loss: 0.0335\n",
      "roc-auc_val: 0.9873\n",
      "143613/143613 [==============================] - 1731s 12ms/step - loss: 0.0335 - val_loss: 0.0407\n",
      "Epoch 9/200\n",
      "143552/143613 [============================>.] - ETA: 0s - loss: 0.0319\n",
      "roc-auc_val: 0.9873\n",
      "143613/143613 [==============================] - 1731s 12ms/step - loss: 0.0319 - val_loss: 0.0415\n",
      "Epoch 10/200\n",
      "143552/143613 [============================>.] - ETA: 0s - loss: 0.0296\n",
      "Epoch 00010: reducing learning rate to 0.00010000000474974513.\n",
      "\n",
      "roc-auc_val: 0.9882\n",
      "143613/143613 [==============================] - 1731s 12ms/step - loss: 0.0296 - val_loss: 0.0434\n",
      "Epoch 11/200\n",
      "143552/143613 [============================>.] - ETA: 0s - loss: 0.0257\n",
      "roc-auc_val: 0.9871\n",
      "143613/143613 [==============================] - 1731s 12ms/step - loss: 0.0257 - val_loss: 0.0460\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f12c24becf8>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x = dataInputTrain,\n",
    "         y = traindf[output_names].values,\n",
    "         batch_size = 64, epochs = 200,\n",
    "         validation_data = [dataInputVal, valdf[output_names].values],\n",
    "         callbacks=[earlyStopping, mcp_save, reduce_lr_loss, tensor_board, roc_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "153164/153164 [==============================] - 909s 6ms/step\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict(dataInputTest, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for counter,i in enumerate(output_names):\n",
    "    test[i] = pred[:,counter]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test[['id'] + output_names].to_csv('data/answers/lstm4.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "todo:\n",
    "- change conv kernel size\n",
    "- try GRU\n",
    "- change dense unit count/number of layers\n",
    "- blending\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
