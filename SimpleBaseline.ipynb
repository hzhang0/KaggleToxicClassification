{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import string\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import unicodedata\n",
    "import sys\n",
    "import collections\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.externals import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "unicodePuncs = [chr(i) for i in range(sys.maxunicode)\n",
    "                      if unicodedata.category(chr(i)).startswith('P')]\n",
    "stopwords += ([i for i in string.punctuation] + ['--', '\\'\\'', '``', '...'])\n",
    "stopwords += unicodePuncs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class BOWExtractor():      \n",
    "    def __init__(self, ngrams_to_take = {1: 100, 2: 50}, stopwords=[], tokenizer = nltk.word_tokenize, unicodeNormalize = True, binary = False):\n",
    "        self.ngrams_to_take = ngrams_to_take\n",
    "        self.stopwords = stopwords\n",
    "        self.tokenizer = tokenizer\n",
    "        self.unicodeNormalize = unicodeNormalize\n",
    "        self.binary = binary\n",
    "    \n",
    "    def hasnum(self,s):\n",
    "        return any(i.isdigit() for i in s)\n",
    "    \n",
    "    def hasPunc(self, s):\n",
    "        return any(i in string.punctuation for i in s)\n",
    "    \n",
    "    def preprocess(self, series):\n",
    "        if self.unicodeNormalize:\n",
    "            series = series.apply(lambda x: unicodedata.normalize('NFKD', x).encode('ascii','ignore').decode('utf-8'))\n",
    "        toks = series.apply(lambda x: list(filter(lambda z: z not in self.stopwords, map(lambda y: y.lower(),self.tokenizer(x)))))\n",
    "        toks = toks.apply(lambda x: [i for i in x if not self.hasPunc(i) and not self.hasnum(i)])\n",
    "        return toks\n",
    "    \n",
    "    def getngrams(self, lst, n=2):\n",
    "        ans = []\n",
    "        for i in range(len(lst) - n+1):\n",
    "            ans.append([lst[i+j] for j in range(n)])\n",
    "        return ans\n",
    "    \n",
    "    def flatten(self, x):\n",
    "        if isinstance(x, (np.ndarray, list, tuple)):\n",
    "            lst = []\n",
    "            for i in x:\n",
    "                lst += self.flatten(i)\n",
    "            return lst\n",
    "        else:\n",
    "            return [x]\n",
    "    \n",
    "    def fit(self, series): #input is a pandas series of strings\n",
    "        assert(isinstance(series.iloc[0], str))\n",
    "        toks = self.preprocess(series)\n",
    "        self.most_common_ngrams = {}\n",
    "        for i in self.ngrams_to_take.keys():\n",
    "            if i == 1:\n",
    "                self.most_common_ngrams[i] = {i[0]: i[1] for i in nltk.FreqDist(self.flatten(toks.values)).most_common(self.ngrams_to_take[i])}\n",
    "            else:\n",
    "                ngrams = [j for i in toks for j in self.getngrams(i)]\n",
    "                self.most_common_ngrams[i] = {i[0]: i[1] for i in collections.Counter(map(tuple, ngrams)).most_common(self.ngrams_to_take[i])}\n",
    "        self.features = [j for i in self.most_common_ngrams.keys() for j in self.most_common_ngrams[i].keys()]\n",
    "        return self\n",
    "            \n",
    "    def transform(self, series): #input is a pandas series of strings, output is a 2d numpy array, in the order of self.features\n",
    "        ngrams = {}\n",
    "        toks = self.preprocess(series)\n",
    "        for i in self.ngrams_to_take.keys():\n",
    "            if i == 1:\n",
    "                ngrams[1] = toks\n",
    "            else:\n",
    "                ngrams[i] = toks.apply(lambda x: self.getngrams(x, i))\n",
    "        ans = np.zeros(shape = (len(series), len(self.features),), dtype='int16')\n",
    "        # loop through each feature\n",
    "        for count, i in enumerate(self.features):\n",
    "            if isinstance(i, str):\n",
    "                ans[:, count] = ngrams[1].apply(lambda x: x.count(i)).values\n",
    "            else: #tuple\n",
    "                ans[:, count] = ngrams[len(i)].apply(lambda x: x.count(i)).values\n",
    "        if self.binary:\n",
    "            ans = (ans>0).astype(int)\n",
    "        return ans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('data/train.csv')\n",
    "test = pd.read_csv('data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000113f07ec002fd</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0001b41b1c6bb37e</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0001d958c54c6e35</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text  toxic  \\\n",
       "0  0000997932d777bf  Explanation\\nWhy the edits made under my usern...      0   \n",
       "1  000103f0d9cfb60f  D'aww! He matches this background colour I'm s...      0   \n",
       "2  000113f07ec002fd  Hey man, I'm really not trying to edit war. It...      0   \n",
       "3  0001b41b1c6bb37e  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
       "4  0001d958c54c6e35  You, sir, are my hero. Any chance you remember...      0   \n",
       "\n",
       "   severe_toxic  obscene  threat  insult  identity_hate  \n",
       "0             0        0       0       0              0  \n",
       "1             0        0       0       0              0  \n",
       "2             0        0       0       0              0  \n",
       "3             0        0       0       0              0  \n",
       "4             0        0       0       0              0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output_names = ['toxic','severe_toxic','obscene','threat','insult','identity_hate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>144277</td>\n",
       "      <td>157976</td>\n",
       "      <td>151122</td>\n",
       "      <td>159093</td>\n",
       "      <td>151694</td>\n",
       "      <td>158166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15294</td>\n",
       "      <td>1595</td>\n",
       "      <td>8449</td>\n",
       "      <td>478</td>\n",
       "      <td>7877</td>\n",
       "      <td>1405</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    toxic  severe_toxic  obscene  threat  insult  identity_hate\n",
       "0  144277        157976   151122  159093  151694         158166\n",
       "1   15294          1595     8449     478    7877           1405"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[output_names].apply(pd.value_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#traindf, valdf = train_test_split(train, test_size = 0.1, random_state = 42, stratify = train.threat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# bow= BOWExtractor(ngrams_to_take = {1:2400, 2:1600, 3:400},stopwords = stopwords).fit(train['comment_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train_mat = bow.transform(train['comment_text']).astype('int16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# tf = TfidfVectorizer(input = 'content', analyzer = 'word', \n",
    "#                      tokenizer = nltk.word_tokenize, ngram_range = (1, 4), \n",
    "#                      stop_words = stopwords, max_features = 200000, dtype='int16').fit(train['comment_text'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train_mat = tf.transform(train['comment_text'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train_mat.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf = TfidfVectorizer(input = 'content', analyzer = 'word', \n",
    "                     tokenizer = nltk.word_tokenize, ngram_range = (1, 4), \n",
    "                     stop_words = stopwords, max_features = 100000, dtype='int16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pipe = Pipeline(steps = [\n",
    "    ('tfidf', tf),\n",
    "    ('svm', SVC(kernel='linear', random_state = 10, probability=True))    \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 3 candidates, totalling 9 fits\n",
      "[CV] svm__C=0.1 ......................................................\n",
      "[CV] svm__C=0.1 ......................................................\n",
      "[CV] svm__C=0.1 ......................................................\n",
      "[CV] svm__C=1.0 ......................................................\n",
      "[CV] ............. svm__C=0.1, score=0.9353129697998771, total=23.8min\n",
      "[CV] svm__C=1.0 ......................................................\n",
      "[CV] ............. svm__C=0.1, score=0.9371224020856562, total=25.5min\n",
      "[CV] svm__C=1.0 ......................................................\n",
      "[CV] ............. svm__C=1.0, score=0.9360261518034818, total=26.4min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done   3 out of   9 | elapsed: 29.6min remaining: 59.2min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] svm__C=10.0 .....................................................\n",
      "[CV] ............. svm__C=0.1, score=0.9446079019368059, total=26.4min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done   4 out of   9 | elapsed: 29.6min remaining: 37.0min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] svm__C=10.0 .....................................................\n",
      "[CV] ............. svm__C=1.0, score=0.9347505842313297, total=24.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done   5 out of   9 | elapsed: 53.7min remaining: 43.0min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] svm__C=10.0 .....................................................\n",
      "[CV] .............. svm__C=1.0, score=0.944916935126062, total=26.3min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done   6 out of   9 | elapsed: 58.0min remaining: 29.0min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ............ svm__C=10.0, score=0.9192984205229078, total=31.6min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done   7 out of   9 | elapsed: 64.2min remaining: 18.3min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ............ svm__C=10.0, score=0.9273358223222844, total=32.4min\n",
      "[CV] ............ svm__C=10.0, score=0.9392404306823285, total=32.3min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done   9 out of   9 | elapsed: 88.6min remaining:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done   9 out of   9 | elapsed: 88.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed calculation for severe_toxic\n",
      "Fitting 3 folds for each of 3 candidates, totalling 9 fits\n",
      "[CV] svm__C=0.1 ......................................................\n",
      "[CV] svm__C=0.1 ......................................................\n",
      "[CV] svm__C=0.1 ......................................................\n",
      "[CV] svm__C=1.0 ......................................................\n",
      "[CV] ............. svm__C=0.1, score=0.9785381138928173, total=74.9min\n",
      "[CV] svm__C=1.0 ......................................................\n",
      "[CV] ............. svm__C=0.1, score=0.9779083351417759, total=76.6min\n",
      "[CV] svm__C=1.0 ......................................................\n",
      "[CV] ............. svm__C=0.1, score=0.9767456858775903, total=78.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done   3 out of   9 | elapsed: 86.0min remaining: 171.9min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] svm__C=10.0 .....................................................\n",
      "[CV] .............. svm__C=1.0, score=0.973568213842813, total=89.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done   4 out of   9 | elapsed: 96.7min remaining: 120.8min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] svm__C=10.0 .....................................................\n",
      "[CV] ............. svm__C=1.0, score=0.9730005637377869, total=81.9min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done   5 out of   9 | elapsed: 173.8min remaining: 139.0min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] svm__C=10.0 .....................................................\n",
      "[CV] .............. svm__C=1.0, score=0.975131256130282, total=85.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done   6 out of   9 | elapsed: 175.4min remaining: 87.7min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ........... svm__C=10.0, score=0.9578877472543711, total=120.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done   7 out of   9 | elapsed: 213.2min remaining: 60.9min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ........... svm__C=10.0, score=0.9615232041601548, total=138.2min\n",
      "[CV] ............ svm__C=10.0, score=0.958478626746933, total=125.7min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done   9 out of   9 | elapsed: 305.1min remaining:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done   9 out of   9 | elapsed: 305.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed calculation for obscene\n",
      "Fitting 3 folds for each of 3 candidates, totalling 9 fits\n",
      "[CV] svm__C=0.1 ......................................................\n",
      "[CV] svm__C=0.1 ......................................................\n",
      "[CV] svm__C=0.1 ......................................................\n",
      "[CV] svm__C=1.0 ......................................................\n",
      "[CV] ............. svm__C=0.1, score=0.9327357357966368, total=10.0min\n",
      "[CV] svm__C=1.0 ......................................................\n",
      "[CV] ............. svm__C=0.1, score=0.9643519238747148, total=11.2min\n",
      "[CV] svm__C=1.0 ......................................................\n",
      "[CV] ............. svm__C=0.1, score=0.9650860437747995, total=12.9min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done   3 out of   9 | elapsed: 15.0min remaining: 30.1min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] svm__C=10.0 .....................................................\n",
      "[CV] ............. svm__C=1.0, score=0.9651716095302747, total=13.6min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done   4 out of   9 | elapsed: 15.8min remaining: 19.8min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] svm__C=10.0 .....................................................\n",
      "[CV] ............. svm__C=1.0, score=0.9332707260699183, total=13.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done   5 out of   9 | elapsed: 27.3min remaining: 21.8min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] svm__C=10.0 .....................................................\n",
      "[CV] ............. svm__C=1.0, score=0.9650639847655265, total=14.5min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done   6 out of   9 | elapsed: 30.0min remaining: 15.0min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ............ svm__C=10.0, score=0.9534515778506911, total=15.3min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done   7 out of   9 | elapsed: 32.5min remaining:  9.3min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ............ svm__C=10.0, score=0.9284033938141558, total=15.0min\n",
      "[CV] ............ svm__C=10.0, score=0.9610206632432508, total=13.6min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done   9 out of   9 | elapsed: 42.7min remaining:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done   9 out of   9 | elapsed: 42.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed calculation for threat\n",
      "Fitting 3 folds for each of 3 candidates, totalling 9 fits\n",
      "[CV] svm__C=0.1 ......................................................\n",
      "[CV] svm__C=0.1 ......................................................\n",
      "[CV] svm__C=0.1 ......................................................\n",
      "[CV] svm__C=1.0 ......................................................\n",
      "[CV] ............. svm__C=0.1, score=0.9679747904279509, total=60.8min\n",
      "[CV] svm__C=1.0 ......................................................\n",
      "[CV] ............. svm__C=0.1, score=0.9667754510078693, total=61.6min\n",
      "[CV] svm__C=1.0 ......................................................\n",
      "[CV] ............. svm__C=0.1, score=0.9618376398486892, total=63.9min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done   3 out of   9 | elapsed: 71.4min remaining: 142.8min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] svm__C=10.0 .....................................................\n",
      "[CV] ............. svm__C=1.0, score=0.9632630822354764, total=80.5min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done   4 out of   9 | elapsed: 88.6min remaining: 110.7min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] svm__C=10.0 .....................................................\n",
      "[CV] ............. svm__C=1.0, score=0.9570361728914145, total=80.4min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done   5 out of   9 | elapsed: 156.6min remaining: 125.3min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] svm__C=10.0 .....................................................\n",
      "[CV] ............. svm__C=1.0, score=0.9631608635543452, total=86.2min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done   6 out of   9 | elapsed: 163.5min remaining: 81.7min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ........... svm__C=10.0, score=0.9402228504118241, total=149.6min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done   7 out of   9 | elapsed: 229.1min remaining: 65.4min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ........... svm__C=10.0, score=0.9376114415859357, total=156.4min\n",
      "[CV] ........... svm__C=10.0, score=0.9387510255743783, total=150.2min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done   9 out of   9 | elapsed: 312.9min remaining:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done   9 out of   9 | elapsed: 312.9min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed calculation for insult\n",
      "Fitting 3 folds for each of 3 candidates, totalling 9 fits\n",
      "[CV] svm__C=0.1 ......................................................\n",
      "[CV] svm__C=0.1 ......................................................\n",
      "[CV] svm__C=0.1 ......................................................\n",
      "[CV] svm__C=1.0 ......................................................\n",
      "[CV] ............. svm__C=0.1, score=0.9382748582923875, total=26.9min\n",
      "[CV] svm__C=1.0 ......................................................\n",
      "[CV] ............. svm__C=0.1, score=0.9431100787650235, total=26.9min\n",
      "[CV] svm__C=1.0 ......................................................\n",
      "[CV] ............. svm__C=0.1, score=0.9439159912159798, total=28.8min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done   3 out of   9 | elapsed: 32.0min remaining: 64.1min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] svm__C=10.0 .....................................................\n",
      "[CV] ............. svm__C=1.0, score=0.9366083546079775, total=30.2min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done   4 out of   9 | elapsed: 33.7min remaining: 42.1min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] svm__C=10.0 .....................................................\n",
      "[CV] ............. svm__C=1.0, score=0.9433020225099433, total=28.4min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done   5 out of   9 | elapsed: 61.7min remaining: 49.3min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] svm__C=10.0 .....................................................\n",
      "[CV] ............. svm__C=1.0, score=0.9421698948556807, total=29.6min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done   6 out of   9 | elapsed: 63.1min remaining: 31.6min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ............ svm__C=10.0, score=0.9296927813913134, total=37.7min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done   7 out of   9 | elapsed: 74.7min remaining: 21.3min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ............ svm__C=10.0, score=0.9227244097838209, total=39.5min\n",
      "[CV] ............ svm__C=10.0, score=0.9277373544899435, total=34.6min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done   9 out of   9 | elapsed: 99.0min remaining:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done   9 out of   9 | elapsed: 99.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed calculation for identity_hate\n"
     ]
    }
   ],
   "source": [
    "final_models = []\n",
    "gs_objs = []\n",
    "output_names = ['severe_toxic','obscene','threat','insult','identity_hate']\n",
    "for i in output_names:\n",
    "    param_grid = {'svm__C': 10**np.linspace(-1,1,3),\n",
    "    }\n",
    "    gs = GridSearchCV(estimator = pipe, param_grid = param_grid, scoring = 'roc_auc', \n",
    "                      n_jobs = 4, cv = 3, refit = True, verbose = 10, return_train_score = True).fit(train['comment_text'].values, train[i])\n",
    "    final_models.append(gs.best_estimator_)\n",
    "    gs_objs.append(gs)\n",
    "    print('Completed calculation for', i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "severe_toxic 0.939014354501\n",
      "obscene 0.977730716697\n",
      "threat 0.954502173652\n",
      "insult 0.965529278143\n",
      "identity_hate 0.941766954207\n"
     ]
    }
   ],
   "source": [
    "for a,b in zip(output_names, final_models):\n",
    "    print(a,b.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# test_mat = bow.transform(test['comment_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# test_mat = tf.transform(test['comment_text'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = [model.predict_proba(test['comment_text'].values)[:,1] for model in final_models]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for count,i in enumerate(output_names):\n",
    "    test[i] = pred[count].flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test[['id', 'toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']].to_csv('data/answers/linear_baseline2.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for count,i in enumerate(final_models):\n",
    "    joblib.dump(i, 'weights/svm/'+str(count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ensembling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_svm = pd.read_csv('data/answers/linear_baseline2.csv')\n",
    "pred_logit = pd.read_csv('data/answers/linear_baseline1.csv')\n",
    "ensemble_pred = pred_svm[['id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/haoran/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "weight = 0.75\n",
    "for i in output_names:\n",
    "    ensemble_pred[i] = weight*pred_logit[i]+(1-weight)*pred_svm[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_pred.to_csv('data/answers/linear_ensemble_'+str(weight)+'.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
