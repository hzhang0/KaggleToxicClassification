{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/haoran/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import string\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "from keras.preprocessing import sequence\n",
    "from keras.layers import  Input, Dense, Flatten, Add,\\\n",
    "    BatchNormalization, Concatenate, Dropout, Activation, Input, Embedding, Conv1D, MaxPooling1D, GlobalMaxPooling1D\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Model, load_model\n",
    "import tensorflow as tf\n",
    "from keras import regularizers\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, TensorBoard\n",
    "import keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "# need to modify to work for 6 labels\n",
    "class ROCCallBack(Callback):\n",
    "    def __init__(self,training_data,validation_data):\n",
    "        self.x = training_data[0]\n",
    "        self.y = training_data[1]\n",
    "        self.x_val = validation_data[0]\n",
    "        self.y_val = validation_data[1]\n",
    "\n",
    "    def on_train_begin(self, logs={}):\n",
    "        return\n",
    "\n",
    "    def on_train_end(self, logs={}):\n",
    "        return\n",
    "\n",
    "    def on_epoch_begin(self, epoch, logs={}):\n",
    "        return\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        y_pred = self.model.predict(self.x)\n",
    "        roc = roc_auc_score(self.y, y_pred)\n",
    "        y_pred_val = self.model.predict(self.x_val)\n",
    "        roc_val = roc_auc_score(self.y_val, y_pred_val)\n",
    "        print('\\rroc-auc: %s - roc-auc_val: %s' % (str(round(roc,4)),str(round(roc_val,4))),end=100*' '+'\\n')\n",
    "        return\n",
    "\n",
    "    def on_batch_begin(self, batch, logs={}):\n",
    "        return\n",
    "\n",
    "    def on_batch_end(self, batch, logs={}):\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def flatten(x):\n",
    "    if isinstance(x, (np.ndarray, list, tuple, pd.Series)):\n",
    "        lst = []\n",
    "        for i in x:\n",
    "            lst += flatten(i)\n",
    "        return lst\n",
    "    else:\n",
    "        return [x]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('data/train.csv')\n",
    "test = pd.read_csv('data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000113f07ec002fd</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0001b41b1c6bb37e</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0001d958c54c6e35</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text  toxic  \\\n",
       "0  0000997932d777bf  Explanation\\nWhy the edits made under my usern...      0   \n",
       "1  000103f0d9cfb60f  D'aww! He matches this background colour I'm s...      0   \n",
       "2  000113f07ec002fd  Hey man, I'm really not trying to edit war. It...      0   \n",
       "3  0001b41b1c6bb37e  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
       "4  0001d958c54c6e35  You, sir, are my hero. Any chance you remember...      0   \n",
       "\n",
       "   severe_toxic  obscene  threat  insult  identity_hate  \n",
       "0             0        0       0       0              0  \n",
       "1             0        0       0       0              0  \n",
       "2             0        0       0       0              0  \n",
       "3             0        0       0       0              0  \n",
       "4             0        0       0       0              0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output_names = ['toxic','severe_toxic','obscene','threat','insult','identity_hate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>144277</td>\n",
       "      <td>157976</td>\n",
       "      <td>151122</td>\n",
       "      <td>159093</td>\n",
       "      <td>151694</td>\n",
       "      <td>158166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15294</td>\n",
       "      <td>1595</td>\n",
       "      <td>8449</td>\n",
       "      <td>478</td>\n",
       "      <td>7877</td>\n",
       "      <td>1405</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    toxic  severe_toxic  obscene  threat  insult  identity_hate\n",
       "0  144277        157976   151122  159093  151694         158166\n",
       "1   15294          1595     8449     478    7877           1405"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[output_names].apply(pd.value_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train['tokens'] = train['comment_text'].apply(lambda x: list(filter(lambda z: len(z), map(lambda y: y.lower(), nltk.word_tokenize(x)))))\n",
    "test['tokens'] = test['comment_text'].apply(lambda x: list(filter(lambda z: len(z), map(lambda y: y.lower(), nltk.word_tokenize(x)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [explanation, why, the, edits, made, under, my...\n",
       "1    [d'aww, !, he, matches, this, background, colo...\n",
       "2    [hey, man, ,, i, 'm, really, not, trying, to, ...\n",
       "3    [``, more, i, ca, n't, make, any, real, sugges...\n",
       "4    [you, ,, sir, ,, are, my, hero, ., any, chance...\n",
       "Name: tokens, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['tokens'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train['tokLength'] = train['tokens'].apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    159571.000000\n",
       "mean         80.322201\n",
       "std         120.769777\n",
       "min           1.000000\n",
       "25%          20.000000\n",
       "50%          43.000000\n",
       "75%          89.000000\n",
       "max        4948.000000\n",
       "Name: tokLength, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['tokLength'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAD9CAYAAABX0LttAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f9b94464e80>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train['tokLength'].hist(bins = range(0, 1000, 20),linewidth = 1, edgecolor = 'black' )\n",
    "plt.show()\n",
    "#looks like max_length of 500 should be good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "98.256575442906296"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.percentileofscore(train['tokLength'].values, 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_length = 500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What are the most common words in the texts?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dist = nltk.FreqDist(flatten(train.tokens.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of total tokens in the training set: 12817094\n",
      "Number of unique tokens in the training set: 259285\n"
     ]
    }
   ],
   "source": [
    "print('Number of total tokens in the training set:', dist.N())\n",
    "print('Number of unique tokens in the training set:', dist.B())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('.', 502031),\n",
       " ('the', 495401),\n",
       " (',', 471812),\n",
       " ('to', 296851),\n",
       " (\"''\", 242526),\n",
       " ('i', 236559),\n",
       " ('of', 224008),\n",
       " ('and', 222709),\n",
       " ('you', 216674),\n",
       " ('a', 214116),\n",
       " ('is', 180287),\n",
       " ('that', 160512),\n",
       " ('``', 155372),\n",
       " ('it', 147625),\n",
       " ('in', 144392),\n",
       " ('!', 105576),\n",
       " ('for', 102451),\n",
       " ('this', 96943),\n",
       " ('not', 96581),\n",
       " (')', 90711),\n",
       " ('on', 89409),\n",
       " ('(', 85085),\n",
       " ('be', 83326),\n",
       " (':', 82772),\n",
       " ('as', 77269),\n",
       " ('have', 73939),\n",
       " ('are', 73404),\n",
       " ('?', 71692),\n",
       " (\"'s\", 66767),\n",
       " ('your', 63258),\n",
       " ('do', 62602),\n",
       " ('with', 59498),\n",
       " ('if', 58363),\n",
       " (\"n't\", 57137),\n",
       " ('article', 56859),\n",
       " ('was', 56537),\n",
       " ('or', 52514),\n",
       " ('but', 50938),\n",
       " ('page', 45656),\n",
       " ('my', 45520),\n",
       " ('wikipedia', 45418),\n",
       " ('an', 44513),\n",
       " ('from', 41411),\n",
       " ('by', 41040),\n",
       " ('at', 39430),\n",
       " ('can', 37244),\n",
       " ('about', 37043),\n",
       " ('me', 37025),\n",
       " ('so', 35968),\n",
       " ('what', 35291)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist.most_common(n=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load GloVe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f = open('data/glove.42B.300d.txt', 'r', encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_unique_tokens = set(flatten(train.tokens.values)).union(set(flatten(test.tokens.values)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embeddings = {}\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    # Whole GloVe embeddings doesn't fit in my GPU memory, so only take words which appear in data for now. \n",
    "    # Can always swap weights for embedding layer after model training\n",
    "    if word in all_unique_tokens:\n",
    "        coefs = np.array(values[1:], dtype = 'float32')\n",
    "        embeddings[word] = coefs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(10)\n",
    "embeddings['<UNK>'] = np.random.normal(scale = 0.6,size = embeddings['.'].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What are the most common words not in the vocab?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "notInVocab = []\n",
    "for i in dist.most_common():\n",
    "    if i[0] not in embeddings.keys() and i[1]>100:\n",
    "        notInVocab.append((i[0], i[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('•', 5300),\n",
       " ('==', 3145),\n",
       " ('~~~~', 1472),\n",
       " ('style=', 1303),\n",
       " ('·', 1109),\n",
       " ('|-', 868),\n",
       " ('*', 730),\n",
       " ('f5fffa', 713),\n",
       " ('..', 683),\n",
       " ('width=', 667),\n",
       " ('|style=', 635),\n",
       " ('====', 627),\n",
       " ('yourselfgo', 621),\n",
       " ('—preceding', 540),\n",
       " ('border:1px', 523),\n",
       " ('//en.wikipedia.org/w/index.php', 471),\n",
       " (\"'image\", 420),\n",
       " ('philippineslong', 420),\n",
       " ('cellpadding=', 372),\n",
       " ('pro-assad.hanibal911you', 345),\n",
       " ('bitches.fuck', 333),\n",
       " ('deneid', 331),\n",
       " ('rice=', 330),\n",
       " ('three-revert', 328),\n",
       " (\"'fuck\", 325),\n",
       " ('\\u200e', 321),\n",
       " ('pagedelete', 312),\n",
       " ('|class=', 308),\n",
       " ('notrhbysouthbanof', 308),\n",
       " ('→', 307),\n",
       " ('mainpagebg', 304),\n",
       " ('//', 304),\n",
       " ('an/i', 292),\n",
       " ('admin-', 289),\n",
       " ('criminalwar', 279),\n",
       " ('bunksteve', 278),\n",
       " ('||', 269),\n",
       " ('marcolfuck', 260),\n",
       " ('boymamas', 258),\n",
       " ('penis/////small', 249),\n",
       " (\"'the\", 244),\n",
       " ('edgar181', 236),\n",
       " ('//en.wikipedia.org/wiki/wikipedia', 228),\n",
       " ('tommy2010', 228),\n",
       " ('securityfuck', 227),\n",
       " ('edit-warring', 224),\n",
       " ('bastered==bastered', 217),\n",
       " ('youbollocks', 217),\n",
       " ('fart.china', 216),\n",
       " ('//en.wikipedia.org/wiki/user_talk', 213),\n",
       " ('concernthanks', 212),\n",
       " ('ancestryfuck-off-jewish', 207),\n",
       " ('//www.youtube.com/watch', 197),\n",
       " ('cellspacing=', 190),\n",
       " ('j.delanoy', 189),\n",
       " ('deleted.this', 185),\n",
       " ('sitush', 182),\n",
       " ('fan-1967', 180),\n",
       " ('centraliststupid', 179),\n",
       " ('nhrhs2010', 176),\n",
       " ('wp:3rr', 166),\n",
       " ('created/took', 158),\n",
       " ('supertr0ll', 151),\n",
       " ('neiln', 150),\n",
       " ('☎', 148),\n",
       " ('bleachanhero', 148),\n",
       " ('aidsaids', 146),\n",
       " ('fatuorum', 143),\n",
       " ('daedalus969', 139),\n",
       " ('bitchmattythewhite', 139),\n",
       " ('fool.what', 139),\n",
       " ('bbb23', 136),\n",
       " ('//en.wikipedia.org/wiki/talk', 133),\n",
       " (':i', 130),\n",
       " (\"'u\", 128),\n",
       " ('haahhahahah', 128),\n",
       " ('cheesei', 126),\n",
       " ('←', 123),\n",
       " ('talk|contribs', 120),\n",
       " ('border:0', 119),\n",
       " ('padding:0', 119),\n",
       " ('8===d~~penis', 118),\n",
       " ('|image=', 118),\n",
       " ('==because', 115),\n",
       " ('noticeboard/incidents', 114),\n",
       " ('084080', 114),\n",
       " ('=en', 112),\n",
       " ('class=', 111),\n",
       " ('cuntliz', 111),\n",
       " ('✉', 110),\n",
       " ('//en.wikipedia.org/wiki/user', 109),\n",
       " ('guidelines.', 109),\n",
       " ('►', 108),\n",
       " ('pennnis', 105),\n",
       " ('pensnsnniensnsn', 105),\n",
       " ('=1', 104),\n",
       " ('nl33ers', 102),\n",
       " ('itsuck', 101)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "notInVocab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "idx2word = {count:i for count, i in enumerate(embeddings.keys())}\n",
    "word2idx = {idx2word[i]: i for i in idx2word.keys()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1674\n",
      "211860\n",
      "could\n"
     ]
    }
   ],
   "source": [
    "print(word2idx['testing'])\n",
    "print(word2idx['<UNK>'])\n",
    "print(idx2word[123])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_factors = 300\n",
    "vocab_size = len(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "zero_vector_idx = vocab_size #place blank character last\n",
    "idx2word[zero_vector_idx] = ''\n",
    "word2idx[''] = zero_vector_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_emb():\n",
    "    emb = np.zeros((vocab_size+1,n_factors), dtype = 'float32')\n",
    "    for i in range(0, vocab_size):\n",
    "        word = idx2word[i]\n",
    "        emb[i,:] = embeddings[word] #each row is a word\n",
    "    return emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "emb = create_emb()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(211862, 300)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# parse train/test sets\n",
    "table = str.maketrans(\"\",\"\", string.punctuation)\n",
    "def toksToInds(listToks):\n",
    "    ans = []\n",
    "    for count, i in enumerate(listToks):\n",
    "        try:\n",
    "            ans.append(word2idx[i])\n",
    "        except KeyError:\n",
    "            temp = i.translate(table)\n",
    "            if temp and temp in word2idx.keys():\n",
    "                ans.append(word2idx[temp])\n",
    "            else:\n",
    "                ans.append(word2idx['<UNK>'])        \n",
    "    return np.array(ans)\n",
    "\n",
    "train['idxInput'] = train['tokens'].apply(toksToInds)\n",
    "test['idxInput'] = test['tokens'].apply(toksToInds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_mat = sequence.pad_sequences(train['idxInput'].values, maxlen = max_length, value = zero_vector_idx)\n",
    "test_mat = sequence.pad_sequences(test['idxInput'].values, maxlen = max_length, value = zero_vector_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(159571, 500)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_mat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"                                                                                                                                                                                                                                                                                                                                                                                                                                                                   explanation why the edits made under my username hardcore metallica fan were reverted ? they were n't vandalisms , just closure on some gas after i voted at new york dolls fac . and please do n't remove the template from the talk page since i 'm retired <UNK>\""
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join([idx2word[i] for i in train_mat[0,:]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train test split\n",
    "indexTrain = np.random.choice(range(train_mat.shape[0]), size = int(0.9*train_mat.shape[0]), replace = False)\n",
    "indexVal = list(set(range(train_mat.shape[0])) - set(indexTrain))\n",
    "dataInputTrain = train_mat[indexTrain]\n",
    "dataInputVal = train_mat[indexVal]\n",
    "traindf = train.loc[indexTrain]\n",
    "valdf = train.loc[indexVal]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14398</td>\n",
       "      <td>15786</td>\n",
       "      <td>15102</td>\n",
       "      <td>15916</td>\n",
       "      <td>15139</td>\n",
       "      <td>15811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1560</td>\n",
       "      <td>172</td>\n",
       "      <td>856</td>\n",
       "      <td>42</td>\n",
       "      <td>819</td>\n",
       "      <td>147</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   toxic  severe_toxic  obscene  threat  insult  identity_hate\n",
       "0  14398         15786    15102   15916   15139          15811\n",
       "1   1560           172      856      42     819            147"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valdf[output_names].apply(pd.value_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# simple starter\n",
    "# vec_input = Input(shape = (max_length,))\n",
    "# x = Embedding(vocab_size+1, n_factors, input_length=max_length,weights = [emb], trainable = False)(vec_input)\n",
    "# x = Conv1D(64,7,activation = 'relu', padding = 'same')(x)\n",
    "# x = MaxPooling1D(2)(x)\n",
    "# # x = Dropout(0.2)(x)\n",
    "\n",
    "# x = Conv1D(64,7,activation = 'relu', padding = 'same')(x)\n",
    "# x = GlobalMaxPooling1D()(x)\n",
    "# x = Dropout(0.5)(x)\n",
    "\n",
    "# x = Dense(32, activation = 'relu', kernel_regularizer=regularizers.l2(1e-4))(x)\n",
    "# x = Dense(len(output_names), activation = 'sigmoid')(x)\n",
    "\n",
    "# model = Model(inputs = vec_input, outputs = x)\n",
    "# model.compile(loss='binary_crossentropy', optimizer=Adam(0.001), metrics=['accuracy'])\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vec_input = Input(shape = (max_length,))\n",
    "x = Embedding(vocab_size+1, n_factors, input_length=max_length,weights = [emb], trainable = False)(vec_input)\n",
    "x = BatchNormalization(axis = -1)(x)\n",
    "#conv 1\n",
    "x = Conv1D(32, 7, activation = 'relu', padding = 'same')(x)\n",
    "x = BatchNormalization(axis = -1)(x)\n",
    "x = MaxPooling1D(pool_size = 2)(x)\n",
    "x = Dropout(0.2)(x)\n",
    "\n",
    "#conv 2\n",
    "x = Conv1D(64, 7, activation = 'relu', padding = 'same')(x)\n",
    "x = BatchNormalization(axis = -1)(x)\n",
    "x = MaxPooling1D(pool_size = 2)(x)\n",
    "x = Dropout(0.2)(x)\n",
    "\n",
    "#conv 3\n",
    "x = Conv1D(64, 7, activation = 'relu', padding = 'same')(x)\n",
    "x = BatchNormalization(axis = -1)(x)\n",
    "x = MaxPooling1D(pool_size = 2)(x)\n",
    "x = Dropout(0.2)(x)\n",
    "\n",
    "#conv 4\n",
    "x = Conv1D(128, 7, activation = 'relu', padding = 'same')(x)\n",
    "x = BatchNormalization(axis = -1)(x)\n",
    "x = MaxPooling1D(pool_size = 2)(x)\n",
    "x = Dropout(0.2)(x)\n",
    "\n",
    "# #conv 5\n",
    "# x = Conv1D(128, 7, activation = 'relu', padding = 'same')(x)\n",
    "# x = BatchNormalization(axis = -1)(x)\n",
    "# x = MaxPooling1D(pool_size = 2)(x)\n",
    "# x = Dropout(0.2)(x)\n",
    "\n",
    "#dense 1\n",
    "x = GlobalMaxPooling1D()(x)\n",
    "x = Dense(64, activation = 'relu')(x)\n",
    "x = BatchNormalization(axis = -1)(x)\n",
    "x = Dropout(0.4)(x)\n",
    "\n",
    "#dense 2\n",
    "x = Dense(128, activation = 'relu')(x)\n",
    "x = BatchNormalization(axis = -1)(x)\n",
    "#x = Dropout(0.4)(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# add output layers\n",
    "outputs = []\n",
    "for i in output_names:\n",
    "    intermediate_act = Dense(units = 128, activation = 'relu')(x)\n",
    "    intermediate_act = BatchNormalization(axis = -1)(intermediate_act)\n",
    "    if i in ['toxic','obscene']:\n",
    "        intermediate_act = Dense(units = 256, activation = 'relu')(intermediate_act)\n",
    "        intermediate_act = BatchNormalization(axis = -1)(intermediate_act)\n",
    "    outputs.append(Dense(units = 1, activation = 'sigmoid', name = i)(intermediate_act))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Model(inputs = vec_input, outputs = outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 500)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 500, 300)     63558600    input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 500, 300)     1200        embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_1 (Conv1D)               (None, 500, 32)      67232       batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 500, 32)      128         conv1d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1D)  (None, 250, 32)      0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 250, 32)      0           max_pooling1d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_2 (Conv1D)               (None, 250, 64)      14400       dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 250, 64)      256         conv1d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1D)  (None, 125, 64)      0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 125, 64)      0           max_pooling1d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_3 (Conv1D)               (None, 125, 64)      28736       dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 125, 64)      256         conv1d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1D)  (None, 62, 64)       0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 62, 64)       0           max_pooling1d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_4 (Conv1D)               (None, 62, 128)      57472       dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 62, 128)      512         conv1d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1D)  (None, 31, 128)      0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 31, 128)      0           max_pooling1d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_1 (GlobalM (None, 128)          0           dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 64)           8256        global_max_pooling1d_1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 64)           256         dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 64)           0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 128)          8320        dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 128)          512         dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 128)          16512       batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 128)          16512       batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 128)          512         dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 128)          512         dense_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 256)          33024       batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 128)          16512       batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 256)          33024       batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 128)          16512       batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 128)          16512       batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 128)          16512       batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 256)          1024        dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 128)          512         dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 256)          1024        dense_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 128)          512         dense_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 128)          512         dense_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 128)          512         dense_10[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "toxic (Dense)                   (None, 1)            257         batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "severe_toxic (Dense)            (None, 1)            129         batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "obscene (Dense)                 (None, 1)            257         batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "threat (Dense)                  (None, 1)            129         batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "insult (Dense)                  (None, 1)            129         batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "identity_hate (Dense)           (None, 1)            129         batch_normalization_15[0][0]     \n",
      "==================================================================================================\n",
      "Total params: 63,917,406\n",
      "Trainable params: 354,686\n",
      "Non-trainable params: 63,562,720\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(Adam(1e-5), loss = 'binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "earlyStopping = EarlyStopping(monitor='val_loss', patience=10, verbose=0, mode='min')\n",
    "mcp_save = ModelCheckpoint('weights/cnn_mdl', save_best_only=True, monitor='val_loss', mode='min')\n",
    "reduce_lr_loss = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5, verbose=1, epsilon=1e-4, mode='min')\n",
    "tensor_board = TensorBoard(log_dir='./logs/run1', write_graph = False,)\n",
    "#roc_callback = ROCCallBack(training_data = [dataInputTrain, ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 143613 samples, validate on 15958 samples\n",
      "Epoch 1/200\n",
      "143613/143613 [==============================] - 195s 1ms/step - loss: 0.5414 - toxic_loss: 0.1571 - severe_toxic_loss: 0.0595 - obscene_loss: 0.1040 - threat_loss: 0.0445 - insult_loss: 0.1134 - identity_hate_loss: 0.0629 - toxic_acc: 0.9409 - severe_toxic_acc: 0.9813 - obscene_acc: 0.9609 - threat_acc: 0.9891 - insult_acc: 0.9551 - identity_hate_acc: 0.9826 - val_loss: 0.3352 - val_toxic_loss: 0.1040 - val_severe_toxic_loss: 0.0375 - val_obscene_loss: 0.0725 - val_threat_loss: 0.0147 - val_insult_loss: 0.0721 - val_identity_hate_loss: 0.0343 - val_toxic_acc: 0.9632 - val_severe_toxic_acc: 0.9892 - val_obscene_acc: 0.9653 - val_threat_acc: 0.9974 - val_insult_acc: 0.9672 - val_identity_hate_acc: 0.9897\n",
      "Epoch 2/200\n",
      "143613/143613 [==============================] - 187s 1ms/step - loss: 0.3269 - toxic_loss: 0.1107 - severe_toxic_loss: 0.0276 - obscene_loss: 0.0652 - threat_loss: 0.0165 - insult_loss: 0.0737 - identity_hate_loss: 0.0332 - toxic_acc: 0.9594 - severe_toxic_acc: 0.9895 - obscene_acc: 0.9742 - threat_acc: 0.9969 - insult_acc: 0.9685 - identity_hate_acc: 0.9911 - val_loss: 0.3361 - val_toxic_loss: 0.1091 - val_severe_toxic_loss: 0.0338 - val_obscene_loss: 0.0622 - val_threat_loss: 0.0139 - val_insult_loss: 0.0827 - val_identity_hate_loss: 0.0344 - val_toxic_acc: 0.9585 - val_severe_toxic_acc: 0.9890 - val_obscene_acc: 0.9768 - val_threat_acc: 0.9974 - val_insult_acc: 0.9635 - val_identity_hate_acc: 0.9908\n",
      "Epoch 3/200\n",
      "143613/143613 [==============================] - 184s 1ms/step - loss: 0.3074 - toxic_loss: 0.1029 - severe_toxic_loss: 0.0261 - obscene_loss: 0.0589 - threat_loss: 0.0160 - insult_loss: 0.0707 - identity_hate_loss: 0.0328 - toxic_acc: 0.9616 - severe_toxic_acc: 0.9897 - obscene_acc: 0.9769 - threat_acc: 0.9969 - insult_acc: 0.9693 - identity_hate_acc: 0.9911 - val_loss: 0.5271 - val_toxic_loss: 0.1803 - val_severe_toxic_loss: 0.0366 - val_obscene_loss: 0.1382 - val_threat_loss: 0.0291 - val_insult_loss: 0.0838 - val_identity_hate_loss: 0.0592 - val_toxic_acc: 0.9439 - val_severe_toxic_acc: 0.9887 - val_obscene_acc: 0.9570 - val_threat_acc: 0.9916 - val_insult_acc: 0.9588 - val_identity_hate_acc: 0.9851\n",
      "Epoch 4/200\n",
      "143613/143613 [==============================] - 184s 1ms/step - loss: 0.2956 - toxic_loss: 0.0976 - severe_toxic_loss: 0.0256 - obscene_loss: 0.0568 - threat_loss: 0.0154 - insult_loss: 0.0683 - identity_hate_loss: 0.0321 - toxic_acc: 0.9637 - severe_toxic_acc: 0.9897 - obscene_acc: 0.9772 - threat_acc: 0.9969 - insult_acc: 0.9703 - identity_hate_acc: 0.9911 - val_loss: 0.3577 - val_toxic_loss: 0.1118 - val_severe_toxic_loss: 0.0430 - val_obscene_loss: 0.0657 - val_threat_loss: 0.0240 - val_insult_loss: 0.0681 - val_identity_hate_loss: 0.0451 - val_toxic_acc: 0.9596 - val_severe_toxic_acc: 0.9878 - val_obscene_acc: 0.9787 - val_threat_acc: 0.9958 - val_insult_acc: 0.9717 - val_identity_hate_acc: 0.9892\n",
      "Epoch 5/200\n",
      "143613/143613 [==============================] - 188s 1ms/step - loss: 0.2845 - toxic_loss: 0.0923 - severe_toxic_loss: 0.0251 - obscene_loss: 0.0539 - threat_loss: 0.0151 - insult_loss: 0.0664 - identity_hate_loss: 0.0317 - toxic_acc: 0.9645 - severe_toxic_acc: 0.9898 - obscene_acc: 0.9785 - threat_acc: 0.9969 - insult_acc: 0.9708 - identity_hate_acc: 0.9911 - val_loss: 0.4107 - val_toxic_loss: 0.1490 - val_severe_toxic_loss: 0.0336 - val_obscene_loss: 0.0723 - val_threat_loss: 0.0153 - val_insult_loss: 0.1017 - val_identity_hate_loss: 0.0388 - val_toxic_acc: 0.9554 - val_severe_toxic_acc: 0.9891 - val_obscene_acc: 0.9743 - val_threat_acc: 0.9972 - val_insult_acc: 0.9518 - val_identity_hate_acc: 0.9907\n",
      "Epoch 6/200\n",
      "143613/143613 [==============================] - 183s 1ms/step - loss: 0.2783 - toxic_loss: 0.0890 - severe_toxic_loss: 0.0251 - obscene_loss: 0.0527 - threat_loss: 0.0152 - insult_loss: 0.0650 - identity_hate_loss: 0.0312 - toxic_acc: 0.9662 - severe_toxic_acc: 0.9896 - obscene_acc: 0.9791 - threat_acc: 0.9969 - insult_acc: 0.9713 - identity_hate_acc: 0.9911 - val_loss: 0.3401 - val_toxic_loss: 0.1153 - val_severe_toxic_loss: 0.0392 - val_obscene_loss: 0.0571 - val_threat_loss: 0.0144 - val_insult_loss: 0.0748 - val_identity_hate_loss: 0.0393 - val_toxic_acc: 0.9605 - val_severe_toxic_acc: 0.9890 - val_obscene_acc: 0.9793 - val_threat_acc: 0.9971 - val_insult_acc: 0.9691 - val_identity_hate_acc: 0.9903\n",
      "Epoch 7/200\n",
      "143552/143613 [============================>.] - ETA: 0s - loss: 0.2709 - toxic_loss: 0.0865 - severe_toxic_loss: 0.0248 - obscene_loss: 0.0503 - threat_loss: 0.0148 - insult_loss: 0.0636 - identity_hate_loss: 0.0309 - toxic_acc: 0.9670 - severe_toxic_acc: 0.9896 - obscene_acc: 0.9798 - threat_acc: 0.9969 - insult_acc: 0.9720 - identity_hate_acc: 0.9911\n",
      "Epoch 00007: reducing learning rate to 0.00010000000474974513.\n",
      "143613/143613 [==============================] - 186s 1ms/step - loss: 0.2709 - toxic_loss: 0.0865 - severe_toxic_loss: 0.0248 - obscene_loss: 0.0503 - threat_loss: 0.0148 - insult_loss: 0.0636 - identity_hate_loss: 0.0309 - toxic_acc: 0.9670 - severe_toxic_acc: 0.9896 - obscene_acc: 0.9798 - threat_acc: 0.9969 - insult_acc: 0.9720 - identity_hate_acc: 0.9911 - val_loss: 3.4891 - val_toxic_loss: 0.1444 - val_severe_toxic_loss: 0.0694 - val_obscene_loss: 0.7207 - val_threat_loss: 0.1288 - val_insult_loss: 0.0814 - val_identity_hate_loss: 2.3444 - val_toxic_acc: 0.9556 - val_severe_toxic_acc: 0.9825 - val_obscene_acc: 0.8945 - val_threat_acc: 0.9657 - val_insult_acc: 0.9633 - val_identity_hate_acc: 0.8021\n",
      "Epoch 8/200\n",
      "143613/143613 [==============================] - 184s 1ms/step - loss: 0.2416 - toxic_loss: 0.0731 - severe_toxic_loss: 0.0224 - obscene_loss: 0.0441 - threat_loss: 0.0141 - insult_loss: 0.0584 - identity_hate_loss: 0.0295 - toxic_acc: 0.9715 - severe_toxic_acc: 0.9903 - obscene_acc: 0.9816 - threat_acc: 0.9970 - insult_acc: 0.9739 - identity_hate_acc: 0.9912 - val_loss: 0.3695 - val_toxic_loss: 0.1225 - val_severe_toxic_loss: 0.0345 - val_obscene_loss: 0.0710 - val_threat_loss: 0.0134 - val_insult_loss: 0.0829 - val_identity_hate_loss: 0.0451 - val_toxic_acc: 0.9636 - val_severe_toxic_acc: 0.9885 - val_obscene_acc: 0.9739 - val_threat_acc: 0.9971 - val_insult_acc: 0.9675 - val_identity_hate_acc: 0.9892\n",
      "Epoch 9/200\n",
      "143613/143613 [==============================] - 183s 1ms/step - loss: 0.2350 - toxic_loss: 0.0701 - severe_toxic_loss: 0.0223 - obscene_loss: 0.0425 - threat_loss: 0.0137 - insult_loss: 0.0573 - identity_hate_loss: 0.0291 - toxic_acc: 0.9729 - severe_toxic_acc: 0.9904 - obscene_acc: 0.9827 - threat_acc: 0.9970 - insult_acc: 0.9745 - identity_hate_acc: 0.9912 - val_loss: 0.3649 - val_toxic_loss: 0.1233 - val_severe_toxic_loss: 0.0347 - val_obscene_loss: 0.0659 - val_threat_loss: 0.0142 - val_insult_loss: 0.0820 - val_identity_hate_loss: 0.0448 - val_toxic_acc: 0.9630 - val_severe_toxic_acc: 0.9889 - val_obscene_acc: 0.9763 - val_threat_acc: 0.9969 - val_insult_acc: 0.9679 - val_identity_hate_acc: 0.9893\n",
      "Epoch 10/200\n",
      "143613/143613 [==============================] - 183s 1ms/step - loss: 0.2318 - toxic_loss: 0.0680 - severe_toxic_loss: 0.0224 - obscene_loss: 0.0418 - threat_loss: 0.0136 - insult_loss: 0.0569 - identity_hate_loss: 0.0290 - toxic_acc: 0.9735 - severe_toxic_acc: 0.9904 - obscene_acc: 0.9828 - threat_acc: 0.9970 - insult_acc: 0.9743 - identity_hate_acc: 0.9912 - val_loss: 0.3730 - val_toxic_loss: 0.1272 - val_severe_toxic_loss: 0.0343 - val_obscene_loss: 0.0626 - val_threat_loss: 0.0151 - val_insult_loss: 0.0856 - val_identity_hate_loss: 0.0482 - val_toxic_acc: 0.9647 - val_severe_toxic_acc: 0.9888 - val_obscene_acc: 0.9796 - val_threat_acc: 0.9970 - val_insult_acc: 0.9669 - val_identity_hate_acc: 0.9877\n",
      "Epoch 11/200\n",
      "143613/143613 [==============================] - 171s 1ms/step - loss: 0.2280 - toxic_loss: 0.0665 - severe_toxic_loss: 0.0221 - obscene_loss: 0.0412 - threat_loss: 0.0138 - insult_loss: 0.0558 - identity_hate_loss: 0.0286 - toxic_acc: 0.9738 - severe_toxic_acc: 0.9905 - obscene_acc: 0.9831 - threat_acc: 0.9970 - insult_acc: 0.9749 - identity_hate_acc: 0.9912 - val_loss: 0.3762 - val_toxic_loss: 0.1394 - val_severe_toxic_loss: 0.0294 - val_obscene_loss: 0.0688 - val_threat_loss: 0.0148 - val_insult_loss: 0.0831 - val_identity_hate_loss: 0.0407 - val_toxic_acc: 0.9634 - val_severe_toxic_acc: 0.9891 - val_obscene_acc: 0.9764 - val_threat_acc: 0.9967 - val_insult_acc: 0.9687 - val_identity_hate_acc: 0.9895\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f9aa2a956d8>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K.set_value(model.optimizer.lr, 1e-3)\n",
    "model.fit(x = dataInputTrain, \n",
    "          y = [traindf[i] for i in output_names],\n",
    "         batch_size = 64, epochs = 200, validation_data = [dataInputVal, [valdf[i] for i in output_names]],\n",
    "         callbacks=[earlyStopping, mcp_save, reduce_lr_loss, tensor_board])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pseudo Labelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[211862,300]\n\t [[Node: embedding_5_5/embeddings/Assign = Assign[T=DT_FLOAT, _class=[\"loc:@embedding_5_5/embeddings\"], use_locking=true, validate_shape=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](embedding_5_5/embeddings, embedding_5_5/random_uniform)]]\n\nCaused by op 'embedding_5_5/embeddings/Assign', defined at:\n  File \"/home/haoran/anaconda3/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/haoran/anaconda3/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/haoran/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/haoran/anaconda3/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/haoran/anaconda3/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"/home/haoran/anaconda3/lib/python3.6/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/home/haoran/anaconda3/lib/python3.6/site-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/home/haoran/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/haoran/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/home/haoran/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/haoran/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/haoran/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/haoran/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/haoran/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/haoran/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/haoran/anaconda3/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/haoran/anaconda3/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/haoran/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2698, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/haoran/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2802, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/haoran/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2862, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-401-dc1e8f026964>\", line 1, in <module>\n    model = load_model('weights/cnn_mdl')\n  File \"/home/haoran/anaconda3/lib/python3.6/site-packages/keras/models.py\", line 240, in load_model\n    model = model_from_config(model_config, custom_objects=custom_objects)\n  File \"/home/haoran/anaconda3/lib/python3.6/site-packages/keras/models.py\", line 314, in model_from_config\n    return layer_module.deserialize(config, custom_objects=custom_objects)\n  File \"/home/haoran/anaconda3/lib/python3.6/site-packages/keras/layers/__init__.py\", line 55, in deserialize\n    printable_module_name='layer')\n  File \"/home/haoran/anaconda3/lib/python3.6/site-packages/keras/utils/generic_utils.py\", line 139, in deserialize_keras_object\n    list(custom_objects.items())))\n  File \"/home/haoran/anaconda3/lib/python3.6/site-packages/keras/engine/topology.py\", line 2500, in from_config\n    process_node(layer, node_data)\n  File \"/home/haoran/anaconda3/lib/python3.6/site-packages/keras/engine/topology.py\", line 2457, in process_node\n    layer(input_tensors[0], **kwargs)\n  File \"/home/haoran/anaconda3/lib/python3.6/site-packages/keras/engine/topology.py\", line 576, in __call__\n    self.build(input_shapes[0])\n  File \"/home/haoran/anaconda3/lib/python3.6/site-packages/keras/layers/embeddings.py\", line 101, in build\n    dtype=self.dtype)\n  File \"/home/haoran/anaconda3/lib/python3.6/site-packages/keras/legacy/interfaces.py\", line 87, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/haoran/anaconda3/lib/python3.6/site-packages/keras/engine/topology.py\", line 400, in add_weight\n    constraint=constraint)\n  File \"/home/haoran/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\", line 380, in variable\n    v = tf.Variable(value, dtype=tf.as_dtype(dtype), name=name)\n  File \"/home/haoran/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/variables.py\", line 213, in __init__\n    constraint=constraint)\n  File \"/home/haoran/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/variables.py\", line 346, in _init_from_args\n    validate_shape=validate_shape).op\n  File \"/home/haoran/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/state_ops.py\", line 276, in assign\n    validate_shape=validate_shape)\n  File \"/home/haoran/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/gen_state_ops.py\", line 57, in assign\n    use_locking=use_locking, name=name)\n  File \"/home/haoran/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/haoran/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 2956, in create_op\n    op_def=op_def)\n  File \"/home/haoran/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1470, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[211862,300]\n\t [[Node: embedding_5_5/embeddings/Assign = Assign[T=DT_FLOAT, _class=[\"loc:@embedding_5_5/embeddings\"], use_locking=true, validate_shape=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](embedding_5_5/embeddings, embedding_5_5/random_uniform)]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1302\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[1;32m    472\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 473\u001b[0;31m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[1;32m    474\u001b[0m     \u001b[0;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[211862,300]\n\t [[Node: embedding_5_5/embeddings/Assign = Assign[T=DT_FLOAT, _class=[\"loc:@embedding_5_5/embeddings\"], use_locking=true, validate_shape=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](embedding_5_5/embeddings, embedding_5_5/random_uniform)]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-401-dc1e8f026964>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'weights/cnn_mdl'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/models.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile)\u001b[0m\n\u001b[1;32m    241\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m         \u001b[0;31m# set weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 243\u001b[0;31m         \u001b[0mtopology\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights_from_hdf5_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model_weights'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    244\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m         \u001b[0;31m# Early return if compilation is not required.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/topology.py\u001b[0m in \u001b[0;36mload_weights_from_hdf5_group\u001b[0;34m(f, layers)\u001b[0m\n\u001b[1;32m   3140\u001b[0m                              ' elements.')\n\u001b[1;32m   3141\u001b[0m         \u001b[0mweight_value_tuples\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msymbolic_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3142\u001b[0;31m     \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_set_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight_value_tuples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mbatch_set_value\u001b[0;34m(tuples)\u001b[0m\n\u001b[1;32m   2245\u001b[0m             \u001b[0massign_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0massign_op\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2246\u001b[0m             \u001b[0mfeed_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0massign_placeholder\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2247\u001b[0;31m         \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0massign_ops\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2248\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2249\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mget_session\u001b[0;34m()\u001b[0m\n\u001b[1;32m    186\u001b[0m                     \u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_keras_initialized\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0muninitialized_vars\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m                     \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariables_initializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muninitialized_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1120\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1121\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1315\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1317\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1318\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1334\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1335\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1336\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1337\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1338\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[211862,300]\n\t [[Node: embedding_5_5/embeddings/Assign = Assign[T=DT_FLOAT, _class=[\"loc:@embedding_5_5/embeddings\"], use_locking=true, validate_shape=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](embedding_5_5/embeddings, embedding_5_5/random_uniform)]]\n\nCaused by op 'embedding_5_5/embeddings/Assign', defined at:\n  File \"/home/haoran/anaconda3/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/haoran/anaconda3/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/haoran/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/haoran/anaconda3/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/haoran/anaconda3/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"/home/haoran/anaconda3/lib/python3.6/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/home/haoran/anaconda3/lib/python3.6/site-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/home/haoran/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/haoran/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/home/haoran/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/haoran/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/haoran/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/haoran/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/haoran/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/haoran/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/haoran/anaconda3/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/haoran/anaconda3/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/haoran/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2698, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/haoran/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2802, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/haoran/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2862, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-401-dc1e8f026964>\", line 1, in <module>\n    model = load_model('weights/cnn_mdl')\n  File \"/home/haoran/anaconda3/lib/python3.6/site-packages/keras/models.py\", line 240, in load_model\n    model = model_from_config(model_config, custom_objects=custom_objects)\n  File \"/home/haoran/anaconda3/lib/python3.6/site-packages/keras/models.py\", line 314, in model_from_config\n    return layer_module.deserialize(config, custom_objects=custom_objects)\n  File \"/home/haoran/anaconda3/lib/python3.6/site-packages/keras/layers/__init__.py\", line 55, in deserialize\n    printable_module_name='layer')\n  File \"/home/haoran/anaconda3/lib/python3.6/site-packages/keras/utils/generic_utils.py\", line 139, in deserialize_keras_object\n    list(custom_objects.items())))\n  File \"/home/haoran/anaconda3/lib/python3.6/site-packages/keras/engine/topology.py\", line 2500, in from_config\n    process_node(layer, node_data)\n  File \"/home/haoran/anaconda3/lib/python3.6/site-packages/keras/engine/topology.py\", line 2457, in process_node\n    layer(input_tensors[0], **kwargs)\n  File \"/home/haoran/anaconda3/lib/python3.6/site-packages/keras/engine/topology.py\", line 576, in __call__\n    self.build(input_shapes[0])\n  File \"/home/haoran/anaconda3/lib/python3.6/site-packages/keras/layers/embeddings.py\", line 101, in build\n    dtype=self.dtype)\n  File \"/home/haoran/anaconda3/lib/python3.6/site-packages/keras/legacy/interfaces.py\", line 87, in wrapper\n    return func(*args, **kwargs)\n  File \"/home/haoran/anaconda3/lib/python3.6/site-packages/keras/engine/topology.py\", line 400, in add_weight\n    constraint=constraint)\n  File \"/home/haoran/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\", line 380, in variable\n    v = tf.Variable(value, dtype=tf.as_dtype(dtype), name=name)\n  File \"/home/haoran/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/variables.py\", line 213, in __init__\n    constraint=constraint)\n  File \"/home/haoran/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/variables.py\", line 346, in _init_from_args\n    validate_shape=validate_shape).op\n  File \"/home/haoran/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/state_ops.py\", line 276, in assign\n    validate_shape=validate_shape)\n  File \"/home/haoran/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/gen_state_ops.py\", line 57, in assign\n    use_locking=use_locking, name=name)\n  File \"/home/haoran/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/haoran/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 2956, in create_op\n    op_def=op_def)\n  File \"/home/haoran/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1470, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[211862,300]\n\t [[Node: embedding_5_5/embeddings/Assign = Assign[T=DT_FLOAT, _class=[\"loc:@embedding_5_5/embeddings\"], use_locking=true, validate_shape=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](embedding_5_5/embeddings, embedding_5_5/random_uniform)]]\n"
     ]
    }
   ],
   "source": [
    "model = load_model('weights/cnn_mdl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 143613 samples, validate on 15958 samples\n",
      "Epoch 1/1\n",
      "143613/143613 [==============================] - 184s 1ms/step - loss: 0.3083 - toxic_loss: 0.1049 - severe_toxic_loss: 0.0256 - obscene_loss: 0.0595 - threat_loss: 0.0153 - insult_loss: 0.0707 - identity_hate_loss: 0.0324 - toxic_acc: 0.9609 - severe_toxic_acc: 0.9898 - obscene_acc: 0.9765 - threat_acc: 0.9970 - insult_acc: 0.9699 - identity_hate_acc: 0.9912 - val_loss: 0.3146 - val_toxic_loss: 0.1044 - val_severe_toxic_loss: 0.0264 - val_obscene_loss: 0.0613 - val_threat_loss: 0.0136 - val_insult_loss: 0.0764 - val_identity_hate_loss: 0.0326 - val_toxic_acc: 0.9581 - val_severe_toxic_acc: 0.9893 - val_obscene_acc: 0.9765 - val_threat_acc: 0.9974 - val_insult_acc: 0.9659 - val_identity_hate_acc: 0.9908\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe6b07ec940>"
      ]
     },
     "execution_count": 395,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K.set_value(model.optimizer.lr, 1e-3)\n",
    "model.fit(x = dataInputTrain, \n",
    "          y = [traindf[i] for i in output_names],\n",
    "         batch_size = 64, epochs = 1, validation_data = [dataInputVal, [valdf[i] for i in output_names]],)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.evaluate(x = dataInputVal, y = [valdf[i] for i in output_names])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_unlabeled = model.predict(test_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "earlyStopping = EarlyStopping(monitor='val_loss', patience=10, verbose=0, mode='min')\n",
    "reduce_lr_loss = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5, verbose=1, epsilon=1e-4, mode='min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def shuffleTogether(X, Y):\n",
    "    p = np.random.permutation(X.shape[0])\n",
    "    return X[p,:], [i[p] for i in Y]        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#add test data such that it's about 1/3 of the training set\n",
    "def createPseudoGenerator( XTrain, XTest, YTrain, YTest):\n",
    "    while True:\n",
    "        idxTest = np.random.permutation( XTest.shape[0])[:int((1/2.0)*XTrain.shape[0])]        \n",
    "        idx = np.random.permutation( XTrain.shape[0])\n",
    "        X = np.vstack((XTrain[idx], XTest[idxTest]))\n",
    "        Y = []\n",
    "        for i in range(len(YTrain)):\n",
    "            Y.append(np.concatenate((YTrain[i][idx], YTest[i][idxTest].flatten())))\n",
    "        #X,Y = shuffleTogether(X,Y)\n",
    "        idx0 = 0\n",
    "        batch_size = 64\n",
    "        while True:           \n",
    "            idx1 = idx0 + batch_size\n",
    "            yield X[idx0:idx1 ], [i[idx0:idx1] for i in Y]\n",
    "            idx0 = idx1\n",
    "            if idx1 >= X.shape[0]:\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "  94/3366 [..............................] - ETA: 5:53 - loss: nan - toxic_loss: nan - severe_toxic_loss: nan - obscene_loss: nan - threat_loss: nan - insult_loss: nan - identity_hate_loss: nan - toxic_acc: 0.0080 - severe_toxic_acc: 0.0095 - obscene_acc: 0.0085 - threat_acc: 0.0096 - insult_acc: 0.0086 - identity_hate_acc: 0.0095"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-391-3ddb1a129de1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m          \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdataInputVal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mvaldf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moutput_names\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m          \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mearlyStopping\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmcp_save\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce_lr_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_board\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m          steps_per_epoch = (1.5*len(traindf))//64+1 )\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     85\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     86\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 87\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   2112\u001b[0m                     outs = self.train_on_batch(x, y,\n\u001b[1;32m   2113\u001b[0m                                                \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2114\u001b[0;31m                                                class_weight=class_weight)\n\u001b[0m\u001b[1;32m   2115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2116\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1830\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1831\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1832\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1833\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1834\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2350\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2351\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2352\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2353\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2354\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1120\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1121\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1315\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1317\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1318\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1321\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1325\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1300\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1302\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "K.set_value(model.optimizer.lr, 5e-3)\n",
    "model.fit_generator(createPseudoGenerator(XTrain = dataInputTrain, XTest = test_mat, \n",
    "                                          YTrain = [traindf[i] for i in output_names],\n",
    "                                         YTest = pred_unlabeled) ,\n",
    "         validation_data = [dataInputVal, [valdf[i] for i in output_names]],\n",
    "         callbacks=[earlyStopping, mcp_save, reduce_lr_loss, tensor_board],\n",
    "         steps_per_epoch = (1.5*len(traindf))//64+1 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examining what the model got wrong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_val = model.predict(dataInputVal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for count,i in enumerate(output_names):\n",
    "#     print('---------------' + i + '---------------------')\n",
    "#     dif = (valdf[i] - pred_val[count].flatten()).abs().sort_values(ascending = False)\n",
    "#     most_dif = valdf.loc[dif.index[:2]]\n",
    "#     for count2, j in enumerate(most_dif.iterrows()):\n",
    "#         print('Predicted', pred_val[count].flatten()[valdf[i].index.get_loc(j[0])]\n",
    "#               , 'Actual', j[1][i],\n",
    "#              '\\n',\n",
    "#              j[1]['comment_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred = model.predict(test_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for count,i in enumerate(output_names):\n",
    "    test[i] = pred[count].flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test[['id', 'toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']].to_csv('data/answers/basic_baseline_cnn.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
