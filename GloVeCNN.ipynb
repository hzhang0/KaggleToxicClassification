{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import string\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "from keras.preprocessing import sequence\n",
    "from keras.layers import  Input, Dense, Flatten, Add,\\\n",
    "    BatchNormalization, Concatenate, Dropout, Activation, Input, Embedding, Conv1D, MaxPooling1D, GlobalMaxPooling1D\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Model, load_model\n",
    "import tensorflow as tf\n",
    "from keras import regularizers\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, TensorBoard, Callback\n",
    "import keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "class ROCCallBack(Callback):\n",
    "    def __init__(self,training_data,validation_data):\n",
    "        super().__init__()\n",
    "        self.x = training_data[0]\n",
    "        self.y = training_data[1]\n",
    "        self.x_val = validation_data[0]\n",
    "        self.y_val = validation_data[1]\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        y_pred = self.model.predict(self.x)\n",
    "        y_pred_val = self.model.predict(self.x_val)\n",
    "        roc_train, roc_val = [], []\n",
    "        for counter, i in enumerate(output_names):            \n",
    "            roc_train.append(roc_auc_score(self.y[counter], y_pred[counter].flatten()))            \n",
    "            roc_val.append(roc_auc_score(self.y_val[counter], y_pred_val[counter].flatten())) \n",
    "        print()\n",
    "        print('roc-auc: %s - roc-auc_val: %s' % (str(round(np.mean(roc_train),4)),str(round(np.mean(roc_val),4))))\n",
    "        print('Val ROCs: ' + '    '.join([output_names[counter] + ': ' + str(round(i,4))for counter, i in enumerate(roc_val)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def flatten(x):\n",
    "    if isinstance(x, (np.ndarray, list, tuple, pd.Series)):\n",
    "        lst = []\n",
    "        for i in x:\n",
    "            lst += flatten(i)\n",
    "        return lst\n",
    "    else:\n",
    "        return [x]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('data/train.csv')\n",
    "test = pd.read_csv('data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# use linear preds as pseudo-labeled data\n",
    "linear_preds = pd.read_csv('data/answers/linear_ensemble_0.85_09724.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000113f07ec002fd</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0001b41b1c6bb37e</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0001d958c54c6e35</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text  toxic  \\\n",
       "0  0000997932d777bf  Explanation\\nWhy the edits made under my usern...      0   \n",
       "1  000103f0d9cfb60f  D'aww! He matches this background colour I'm s...      0   \n",
       "2  000113f07ec002fd  Hey man, I'm really not trying to edit war. It...      0   \n",
       "3  0001b41b1c6bb37e  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
       "4  0001d958c54c6e35  You, sir, are my hero. Any chance you remember...      0   \n",
       "\n",
       "   severe_toxic  obscene  threat  insult  identity_hate  \n",
       "0             0        0       0       0              0  \n",
       "1             0        0       0       0              0  \n",
       "2             0        0       0       0              0  \n",
       "3             0        0       0       0              0  \n",
       "4             0        0       0       0              0  "
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>144277</td>\n",
       "      <td>157976</td>\n",
       "      <td>151122</td>\n",
       "      <td>159093</td>\n",
       "      <td>151694</td>\n",
       "      <td>158166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15294</td>\n",
       "      <td>1595</td>\n",
       "      <td>8449</td>\n",
       "      <td>478</td>\n",
       "      <td>7877</td>\n",
       "      <td>1405</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    toxic  severe_toxic  obscene  threat  insult  identity_hate\n",
       "0  144277        157976   151122  159093  151694         158166\n",
       "1   15294          1595     8449     478    7877           1405"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[output_names].apply(pd.value_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output_names = ['toxic','severe_toxic','obscene','threat','insult','identity_hate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train['tokens'] = train['comment_text'].apply(lambda x: list(filter(lambda z: len(z), map(lambda y: y.lower(), nltk.word_tokenize(x)))))\n",
    "test['tokens'] = test['comment_text'].apply(lambda x: list(filter(lambda z: len(z), map(lambda y: y.lower(), nltk.word_tokenize(x)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [explanation, why, the, edits, made, under, my...\n",
       "1    [d'aww, !, he, matches, this, background, colo...\n",
       "2    [hey, man, ,, i, 'm, really, not, trying, to, ...\n",
       "3    [``, more, i, ca, n't, make, any, real, sugges...\n",
       "4    [you, ,, sir, ,, are, my, hero, ., any, chance...\n",
       "Name: tokens, dtype: object"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['tokens'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train['tokLength'] = train['tokens'].apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    159571.000000\n",
       "mean         80.322201\n",
       "std         120.769777\n",
       "min           1.000000\n",
       "25%          20.000000\n",
       "50%          43.000000\n",
       "75%          89.000000\n",
       "max        4948.000000\n",
       "Name: tokLength, dtype: float64"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['tokLength'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAD9CAYAAABX0LttAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fc86f737c88>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train['tokLength'].hist(bins = range(0, 1000, 20),linewidth = 1, edgecolor = 'black' )\n",
    "plt.show()\n",
    "#looks like max_length of 500 should be good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "98.256575442906296"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.percentileofscore(train['tokLength'].values, 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_length = 500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What are the most common words in the texts?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dist = nltk.FreqDist(flatten(train.tokens.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of total tokens in the training set: 12817094\n",
      "Number of unique tokens in the training set: 259285\n"
     ]
    }
   ],
   "source": [
    "print('Number of total tokens in the training set:', dist.N())\n",
    "print('Number of unique tokens in the training set:', dist.B())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('.', 502031),\n",
       " ('the', 495401),\n",
       " (',', 471812),\n",
       " ('to', 296851),\n",
       " (\"''\", 242526),\n",
       " ('i', 236559),\n",
       " ('of', 224008),\n",
       " ('and', 222709),\n",
       " ('you', 216674),\n",
       " ('a', 214116),\n",
       " ('is', 180287),\n",
       " ('that', 160512),\n",
       " ('``', 155372),\n",
       " ('it', 147625),\n",
       " ('in', 144392),\n",
       " ('!', 105576),\n",
       " ('for', 102451),\n",
       " ('this', 96943),\n",
       " ('not', 96581),\n",
       " (')', 90711),\n",
       " ('on', 89409),\n",
       " ('(', 85085),\n",
       " ('be', 83326),\n",
       " (':', 82772),\n",
       " ('as', 77269),\n",
       " ('have', 73939),\n",
       " ('are', 73404),\n",
       " ('?', 71692),\n",
       " (\"'s\", 66767),\n",
       " ('your', 63258),\n",
       " ('do', 62602),\n",
       " ('with', 59498),\n",
       " ('if', 58363),\n",
       " (\"n't\", 57137),\n",
       " ('article', 56859),\n",
       " ('was', 56537),\n",
       " ('or', 52514),\n",
       " ('but', 50938),\n",
       " ('page', 45656),\n",
       " ('my', 45520),\n",
       " ('wikipedia', 45418),\n",
       " ('an', 44513),\n",
       " ('from', 41411),\n",
       " ('by', 41040),\n",
       " ('at', 39430),\n",
       " ('can', 37244),\n",
       " ('about', 37043),\n",
       " ('me', 37025),\n",
       " ('so', 35968),\n",
       " ('what', 35291)]"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist.most_common(n=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load GloVe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f = open('data/glove.42B.300d.txt', 'r', encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_unique_tokens = set(flatten(train.tokens.values)).union(set(flatten(test.tokens.values)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embeddings = {}\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    # Whole GloVe embeddings doesn't fit in my GPU memory, so only take words which appear in data for now. \n",
    "    # Can always swap weights for embedding layer after model training\n",
    "    if word in all_unique_tokens:\n",
    "        coefs = np.array(values[1:], dtype = 'float32')\n",
    "        embeddings[word] = coefs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(10)\n",
    "embeddings['<UNK>'] = np.random.normal(scale = 0.6,size = embeddings['.'].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What are the most common words not in the vocab?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "notInVocab = []\n",
    "for i in dist.most_common():\n",
    "    if i[0] not in embeddings.keys() and i[1]>100:\n",
    "        notInVocab.append((i[0], i[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('•', 5300),\n",
       " ('==', 3145),\n",
       " ('~~~~', 1472),\n",
       " ('style=', 1303),\n",
       " ('·', 1109),\n",
       " ('|-', 868),\n",
       " ('*', 730),\n",
       " ('f5fffa', 713),\n",
       " ('..', 683),\n",
       " ('width=', 667),\n",
       " ('|style=', 635),\n",
       " ('====', 627),\n",
       " ('yourselfgo', 621),\n",
       " ('—preceding', 540),\n",
       " ('border:1px', 523),\n",
       " ('//en.wikipedia.org/w/index.php', 471),\n",
       " (\"'image\", 420),\n",
       " ('philippineslong', 420),\n",
       " ('cellpadding=', 372),\n",
       " ('pro-assad.hanibal911you', 345),\n",
       " ('bitches.fuck', 333),\n",
       " ('deneid', 331),\n",
       " ('rice=', 330),\n",
       " ('three-revert', 328),\n",
       " (\"'fuck\", 325),\n",
       " ('\\u200e', 321),\n",
       " ('pagedelete', 312),\n",
       " ('|class=', 308),\n",
       " ('notrhbysouthbanof', 308),\n",
       " ('→', 307),\n",
       " ('mainpagebg', 304),\n",
       " ('//', 304),\n",
       " ('an/i', 292),\n",
       " ('admin-', 289),\n",
       " ('criminalwar', 279),\n",
       " ('bunksteve', 278),\n",
       " ('||', 269),\n",
       " ('marcolfuck', 260),\n",
       " ('boymamas', 258),\n",
       " ('penis/////small', 249),\n",
       " (\"'the\", 244),\n",
       " ('edgar181', 236),\n",
       " ('//en.wikipedia.org/wiki/wikipedia', 228),\n",
       " ('tommy2010', 228),\n",
       " ('securityfuck', 227),\n",
       " ('edit-warring', 224),\n",
       " ('bastered==bastered', 217),\n",
       " ('youbollocks', 217),\n",
       " ('fart.china', 216),\n",
       " ('//en.wikipedia.org/wiki/user_talk', 213),\n",
       " ('concernthanks', 212),\n",
       " ('ancestryfuck-off-jewish', 207),\n",
       " ('//www.youtube.com/watch', 197),\n",
       " ('cellspacing=', 190),\n",
       " ('j.delanoy', 189),\n",
       " ('deleted.this', 185),\n",
       " ('sitush', 182),\n",
       " ('fan-1967', 180),\n",
       " ('centraliststupid', 179),\n",
       " ('nhrhs2010', 176),\n",
       " ('wp:3rr', 166),\n",
       " ('created/took', 158),\n",
       " ('supertr0ll', 151),\n",
       " ('neiln', 150),\n",
       " ('☎', 148),\n",
       " ('bleachanhero', 148),\n",
       " ('aidsaids', 146),\n",
       " ('fatuorum', 143),\n",
       " ('daedalus969', 139),\n",
       " ('bitchmattythewhite', 139),\n",
       " ('fool.what', 139),\n",
       " ('bbb23', 136),\n",
       " ('//en.wikipedia.org/wiki/talk', 133),\n",
       " (':i', 130),\n",
       " (\"'u\", 128),\n",
       " ('haahhahahah', 128),\n",
       " ('cheesei', 126),\n",
       " ('←', 123),\n",
       " ('talk|contribs', 120),\n",
       " ('border:0', 119),\n",
       " ('padding:0', 119),\n",
       " ('8===d~~penis', 118),\n",
       " ('|image=', 118),\n",
       " ('==because', 115),\n",
       " ('noticeboard/incidents', 114),\n",
       " ('084080', 114),\n",
       " ('=en', 112),\n",
       " ('class=', 111),\n",
       " ('cuntliz', 111),\n",
       " ('✉', 110),\n",
       " ('//en.wikipedia.org/wiki/user', 109),\n",
       " ('guidelines.', 109),\n",
       " ('►', 108),\n",
       " ('pennnis', 105),\n",
       " ('pensnsnniensnsn', 105),\n",
       " ('=1', 104),\n",
       " ('nl33ers', 102),\n",
       " ('itsuck', 101)]"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "notInVocab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "idx2word = {count:i for count, i in enumerate(embeddings.keys())}\n",
    "word2idx = {idx2word[i]: i for i in idx2word.keys()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1674\n",
      "211860\n",
      "could\n"
     ]
    }
   ],
   "source": [
    "print(word2idx['testing'])\n",
    "print(word2idx['<UNK>'])\n",
    "print(idx2word[123])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_factors = 300\n",
    "vocab_size = len(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "zero_vector_idx = vocab_size #place blank character last\n",
    "idx2word[zero_vector_idx] = ''\n",
    "word2idx[''] = zero_vector_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_emb():\n",
    "    emb = np.zeros((vocab_size+1,n_factors), dtype = 'float32')\n",
    "    for i in range(0, vocab_size):\n",
    "        word = idx2word[i]\n",
    "        emb[i,:] = embeddings[word] #each row is a word\n",
    "    return emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "emb = create_emb()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(211862, 300)"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# parse train/test sets\n",
    "table = str.maketrans(\"\",\"\", string.punctuation)\n",
    "def toksToInds(listToks):\n",
    "    ans = []\n",
    "    for count, i in enumerate(listToks):\n",
    "        try:\n",
    "            ans.append(word2idx[i])\n",
    "        except KeyError:\n",
    "            temp = i.translate(table)\n",
    "            if temp and temp in word2idx.keys():\n",
    "                ans.append(word2idx[temp])\n",
    "            else:\n",
    "                ans.append(word2idx['<UNK>'])        \n",
    "    return np.array(ans)\n",
    "\n",
    "train['idxInput'] = train['tokens'].apply(toksToInds)\n",
    "test['idxInput'] = test['tokens'].apply(toksToInds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train test split\n",
    "np.random.seed(10)\n",
    "indexTrain = np.random.choice(range(train.shape[0]), size = int(0.9*train.shape[0]), replace = False)\n",
    "indexVal = list(set(range(train.shape[0])) - set(indexTrain))\n",
    "traindf = train.loc[indexTrain]\n",
    "valdf = train.loc[indexVal]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# only add pseudo labeled data to the training set\n",
    "pseudo = test.merge(linear_preds, how = 'left', on='id').sample(int(train.shape[0]*0.3), random_state = 10).round()\n",
    "pseudo[output_names] = pseudo[output_names].astype(int)\n",
    "traindf = traindf.append(pseudo, ignore_index = True).sample(frac=1, random_state = 10).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataInputTrain = sequence.pad_sequences(traindf['idxInput'].values, maxlen = max_length, value = zero_vector_idx)\n",
    "dataInputVal = sequence.pad_sequences(valdf['idxInput'].values, maxlen = max_length, value = zero_vector_idx)\n",
    "dataInputTest = sequence.pad_sequences(test['idxInput'].values, maxlen = max_length, value = zero_vector_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(191484, 500)"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataInputTrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  . you have a quote , i have multiple full length articles , video , and a minimum of 20 quotes that say he is used gay slurs as a longer trend of prejudice'"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join([idx2word[i] for i in dataInputTrain[0,:]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14401</td>\n",
       "      <td>15793</td>\n",
       "      <td>15111</td>\n",
       "      <td>15916</td>\n",
       "      <td>15150</td>\n",
       "      <td>15816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1557</td>\n",
       "      <td>165</td>\n",
       "      <td>847</td>\n",
       "      <td>42</td>\n",
       "      <td>808</td>\n",
       "      <td>142</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   toxic  severe_toxic  obscene  threat  insult  identity_hate\n",
       "0  14401         15793    15111   15916   15150          15816\n",
       "1   1557           165      847      42     808            142"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valdf[output_names].apply(lambda x: pd.value_counts(np.round(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# simple starter\n",
    "# vec_input = Input(shape = (max_length,))\n",
    "# x = Embedding(vocab_size+1, n_factors, input_length=max_length,weights = [emb], trainable = False)(vec_input)\n",
    "# x = Conv1D(64,7,activation = 'relu', padding = 'same')(x)\n",
    "# x = MaxPooling1D(2)(x)\n",
    "# # x = Dropout(0.2)(x)\n",
    "\n",
    "# x = Conv1D(64,7,activation = 'relu', padding = 'same')(x)\n",
    "# x = GlobalMaxPooling1D()(x)\n",
    "# x = Dropout(0.5)(x)\n",
    "\n",
    "# x = Dense(32, activation = 'relu', kernel_regularizer=regularizers.l2(1e-4))(x)\n",
    "# x = Dense(len(output_names), activation = 'sigmoid')(x)\n",
    "\n",
    "# model = Model(inputs = vec_input, outputs = x)\n",
    "# model.compile(loss='binary_crossentropy', optimizer=Adam(0.001), metrics=['accuracy'])\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vec_input = Input(shape = (max_length,))\n",
    "x = Embedding(vocab_size+1, n_factors, input_length=max_length,weights = [emb], trainable = False)(vec_input)\n",
    "x = BatchNormalization(axis = -1)(x)\n",
    "#conv 1\n",
    "x = Conv1D(32, 7, activation = 'relu', padding = 'same')(x)\n",
    "x = BatchNormalization(axis = -1)(x)\n",
    "x = MaxPooling1D(pool_size = 2)(x)\n",
    "x = Dropout(0.2)(x)\n",
    "\n",
    "#conv 2\n",
    "x = Conv1D(64, 7, activation = 'relu', padding = 'same')(x)\n",
    "x = BatchNormalization(axis = -1)(x)\n",
    "x = MaxPooling1D(pool_size = 2)(x)\n",
    "x = Dropout(0.2)(x)\n",
    "\n",
    "#conv 3\n",
    "x = Conv1D(64, 7, activation = 'relu', padding = 'same')(x)\n",
    "x = BatchNormalization(axis = -1)(x)\n",
    "x = MaxPooling1D(pool_size = 2)(x)\n",
    "x = Dropout(0.2)(x)\n",
    "\n",
    "#conv 4\n",
    "x = Conv1D(128, 7, activation = 'relu', padding = 'same')(x)\n",
    "x = BatchNormalization(axis = -1)(x)\n",
    "x = MaxPooling1D(pool_size = 2)(x)\n",
    "x = Dropout(0.2)(x)\n",
    "\n",
    "# #conv 5\n",
    "# x = Conv1D(128, 7, activation = 'relu', padding = 'same')(x)\n",
    "# x = BatchNormalization(axis = -1)(x)\n",
    "# x = MaxPooling1D(pool_size = 2)(x)\n",
    "# x = Dropout(0.2)(x)\n",
    "\n",
    "#dense 1\n",
    "x = GlobalMaxPooling1D()(x)\n",
    "x = Dense(64, activation = 'relu')(x)\n",
    "x = BatchNormalization(axis = -1)(x)\n",
    "x = Dropout(0.4)(x)\n",
    "\n",
    "#dense 2\n",
    "x = Dense(128, activation = 'relu')(x)\n",
    "x = BatchNormalization(axis = -1)(x)\n",
    "x = Dropout(0.4)(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# add output layers\n",
    "outputs = []\n",
    "for i in output_names:\n",
    "    intermediate_act = Dense(units = 128, activation = 'relu')(x)\n",
    "    intermediate_act = BatchNormalization(axis = -1)(intermediate_act)\n",
    "    if i in ['toxic','obscene']:\n",
    "        intermediate_act = Dense(units = 512, activation = 'relu')(intermediate_act)\n",
    "        intermediate_act = BatchNormalization(axis = -1)(intermediate_act)\n",
    "    outputs.append(Dense(units = 1, activation = 'sigmoid', name = i)(intermediate_act))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Model(inputs = vec_input, outputs = outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            (None, 500)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_3 (Embedding)         (None, 500, 300)     63558600    input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 500, 300)     1200        embedding_3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_9 (Conv1D)               (None, 500, 32)      67232       batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 500, 32)      128         conv1d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_9 (MaxPooling1D)  (None, 250, 32)      0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_11 (Dropout)            (None, 250, 32)      0           max_pooling1d_9[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_10 (Conv1D)              (None, 250, 64)      14400       dropout_11[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 250, 64)      256         conv1d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_10 (MaxPooling1D) (None, 125, 64)      0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_12 (Dropout)            (None, 125, 64)      0           max_pooling1d_10[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_11 (Conv1D)              (None, 125, 64)      28736       dropout_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 125, 64)      256         conv1d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_11 (MaxPooling1D) (None, 62, 64)       0           batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_13 (Dropout)            (None, 62, 64)       0           max_pooling1d_11[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1d_12 (Conv1D)              (None, 62, 128)      57472       dropout_13[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, 62, 128)      512         conv1d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling1d_12 (MaxPooling1D) (None, 31, 128)      0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_14 (Dropout)            (None, 31, 128)      0           max_pooling1d_12[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_3 (GlobalM (None, 128)          0           dropout_14[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_21 (Dense)                (None, 64)           8256        global_max_pooling1d_3[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 64)           256         dense_21[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_15 (Dropout)            (None, 64)           0           batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_22 (Dense)                (None, 128)          8320        dropout_15[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 128)          512         dense_22[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_16 (Dropout)            (None, 128)          0           batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_23 (Dense)                (None, 128)          16512       dropout_16[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_26 (Dense)                (None, 128)          16512       dropout_16[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, 128)          512         dense_23[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, 128)          512         dense_26[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_24 (Dense)                (None, 512)          66048       batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_25 (Dense)                (None, 128)          16512       dropout_16[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_27 (Dense)                (None, 512)          66048       batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_28 (Dense)                (None, 128)          16512       dropout_16[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_29 (Dense)                (None, 128)          16512       dropout_16[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_30 (Dense)                (None, 128)          16512       dropout_16[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, 512)          2048        dense_24[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, 128)          512         dense_25[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, 512)          2048        dense_27[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, 128)          512         dense_28[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, 128)          512         dense_29[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (None, 128)          512         dense_30[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "toxic (Dense)                   (None, 1)            513         batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "severe_toxic (Dense)            (None, 1)            129         batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "obscene (Dense)                 (None, 1)            513         batch_normalization_42[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "threat (Dense)                  (None, 1)            129         batch_normalization_43[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "insult (Dense)                  (None, 1)            129         batch_normalization_44[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "identity_hate (Dense)           (None, 1)            129         batch_normalization_45[0][0]     \n",
      "==================================================================================================\n",
      "Total params: 63,986,014\n",
      "Trainable params: 422,270\n",
      "Non-trainable params: 63,563,744\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(Adam(1e-5), loss = 'binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "earlyStopping = EarlyStopping(monitor='val_loss', patience=10, verbose=0, mode='min')\n",
    "mcp_save = ModelCheckpoint('weights/cnn_mdl', save_best_only=True, monitor='val_loss', mode='min')\n",
    "reduce_lr_loss = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5, verbose=1, epsilon=1e-4, mode='min')\n",
    "tensor_board = TensorBoard(log_dir='./logs/run1', write_graph = False,)\n",
    "roc_callback = ROCCallBack(training_data = [dataInputTrain, [traindf[i] for i in output_names]],\n",
    "                          validation_data = [dataInputVal, [valdf[i] for i in output_names]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 191484 samples, validate on 15958 samples\n",
      "Epoch 1/200\n",
      "191424/191484 [============================>.] - ETA: 0s - loss: 0.5682 - toxic_loss: 0.1766 - severe_toxic_loss: 0.0543 - obscene_loss: 0.1176 - threat_loss: 0.0385 - insult_loss: 0.1237 - identity_hate_loss: 0.0575\n",
      "roc-auc: 0.9543 - roc-auc_val: 0.9528\n",
      "Val ROCs: toxic: 0.9625    severe_toxic: 0.975    obscene: 0.9561    threat: 0.9219    insult: 0.9622    identity_hate: 0.9393\n",
      "191484/191484 [==============================] - 322s 2ms/step - loss: 0.5682 - toxic_loss: 0.1766 - severe_toxic_loss: 0.0543 - obscene_loss: 0.1176 - threat_loss: 0.0385 - insult_loss: 0.1236 - identity_hate_loss: 0.0575 - val_loss: 0.6443 - val_toxic_loss: 0.2015 - val_severe_toxic_loss: 0.0337 - val_obscene_loss: 0.1604 - val_threat_loss: 0.0157 - val_insult_loss: 0.1944 - val_identity_hate_loss: 0.0385\n",
      "Epoch 2/200\n",
      "191424/191484 [============================>.] - ETA: 0s - loss: 0.3652 - toxic_loss: 0.1253 - severe_toxic_loss: 0.0273 - obscene_loss: 0.0787 - threat_loss: 0.0152 - insult_loss: 0.0862 - identity_hate_loss: 0.0325\n",
      "roc-auc: 0.9705 - roc-auc_val: 0.975\n",
      "Val ROCs: toxic: 0.9771    severe_toxic: 0.9844    obscene: 0.9875    threat: 0.9596    insult: 0.9843    identity_hate: 0.9571\n",
      "191484/191484 [==============================] - 308s 2ms/step - loss: 0.3652 - toxic_loss: 0.1253 - severe_toxic_loss: 0.0273 - obscene_loss: 0.0787 - threat_loss: 0.0151 - insult_loss: 0.0862 - identity_hate_loss: 0.0325 - val_loss: 0.3939 - val_toxic_loss: 0.1499 - val_severe_toxic_loss: 0.0312 - val_obscene_loss: 0.0794 - val_threat_loss: 0.0134 - val_insult_loss: 0.0830 - val_identity_hate_loss: 0.0370\n",
      "Epoch 3/200\n",
      "191424/191484 [============================>.] - ETA: 0s - loss: 0.3471 - toxic_loss: 0.1192 - severe_toxic_loss: 0.0263 - obscene_loss: 0.0730 - threat_loss: 0.0146 - insult_loss: 0.0821 - identity_hate_loss: 0.0319\n",
      "roc-auc: 0.9744 - roc-auc_val: 0.9756\n",
      "Val ROCs: toxic: 0.9783    severe_toxic: 0.9842    obscene: 0.9878    threat: 0.9614    insult: 0.9833    identity_hate: 0.9583\n",
      "191484/191484 [==============================] - 308s 2ms/step - loss: 0.3471 - toxic_loss: 0.1192 - severe_toxic_loss: 0.0263 - obscene_loss: 0.0730 - threat_loss: 0.0146 - insult_loss: 0.0821 - identity_hate_loss: 0.0319 - val_loss: 0.3579 - val_toxic_loss: 0.1245 - val_severe_toxic_loss: 0.0335 - val_obscene_loss: 0.0711 - val_threat_loss: 0.0135 - val_insult_loss: 0.0807 - val_identity_hate_loss: 0.0346\n",
      "Epoch 4/200\n",
      "191424/191484 [============================>.] - ETA: 0s - loss: 0.3306 - toxic_loss: 0.1118 - severe_toxic_loss: 0.0251 - obscene_loss: 0.0698 - threat_loss: 0.0144 - insult_loss: 0.0785 - identity_hate_loss: 0.0311\n",
      "roc-auc: 0.9755 - roc-auc_val: 0.9757\n",
      "Val ROCs: toxic: 0.9789    severe_toxic: 0.9835    obscene: 0.9893    threat: 0.9608    insult: 0.9838    identity_hate: 0.9577\n",
      "191484/191484 [==============================] - 308s 2ms/step - loss: 0.3306 - toxic_loss: 0.1118 - severe_toxic_loss: 0.0251 - obscene_loss: 0.0698 - threat_loss: 0.0144 - insult_loss: 0.0785 - identity_hate_loss: 0.0310 - val_loss: 0.3552 - val_toxic_loss: 0.1132 - val_severe_toxic_loss: 0.0336 - val_obscene_loss: 0.0768 - val_threat_loss: 0.0128 - val_insult_loss: 0.0855 - val_identity_hate_loss: 0.0334\n",
      "Epoch 5/200\n",
      "191424/191484 [============================>.] - ETA: 0s - loss: 0.3186 - toxic_loss: 0.1073 - severe_toxic_loss: 0.0250 - obscene_loss: 0.0657 - threat_loss: 0.0143 - insult_loss: 0.0758 - identity_hate_loss: 0.0306\n",
      "roc-auc: 0.9755 - roc-auc_val: 0.9727\n",
      "Val ROCs: toxic: 0.9778    severe_toxic: 0.9829    obscene: 0.987    threat: 0.9504    insult: 0.9814    identity_hate: 0.9564\n",
      "191484/191484 [==============================] - 307s 2ms/step - loss: 0.3187 - toxic_loss: 0.1073 - severe_toxic_loss: 0.0250 - obscene_loss: 0.0657 - threat_loss: 0.0143 - insult_loss: 0.0758 - identity_hate_loss: 0.0306 - val_loss: 0.3628 - val_toxic_loss: 0.1216 - val_severe_toxic_loss: 0.0345 - val_obscene_loss: 0.0712 - val_threat_loss: 0.0136 - val_insult_loss: 0.0872 - val_identity_hate_loss: 0.0346\n",
      "Epoch 6/200\n",
      "191424/191484 [============================>.] - ETA: 0s - loss: 0.3074 - toxic_loss: 0.1028 - severe_toxic_loss: 0.0240 - obscene_loss: 0.0629 - threat_loss: 0.0141 - insult_loss: 0.0734 - identity_hate_loss: 0.0302\n",
      "roc-auc: 0.9764 - roc-auc_val: 0.9714\n",
      "Val ROCs: toxic: 0.9777    severe_toxic: 0.9857    obscene: 0.9872    threat: 0.9369    insult: 0.9816    identity_hate: 0.9595\n",
      "191484/191484 [==============================] - 309s 2ms/step - loss: 0.3073 - toxic_loss: 0.1028 - severe_toxic_loss: 0.0240 - obscene_loss: 0.0629 - threat_loss: 0.0141 - insult_loss: 0.0734 - identity_hate_loss: 0.0302 - val_loss: 0.3166 - val_toxic_loss: 0.1042 - val_severe_toxic_loss: 0.0283 - val_obscene_loss: 0.0619 - val_threat_loss: 0.0136 - val_insult_loss: 0.0771 - val_identity_hate_loss: 0.0316\n",
      "Epoch 7/200\n",
      "191424/191484 [============================>.] - ETA: 0s - loss: 0.3002 - toxic_loss: 0.0992 - severe_toxic_loss: 0.0239 - obscene_loss: 0.0610 - threat_loss: 0.0139 - insult_loss: 0.0722 - identity_hate_loss: 0.0300\n",
      "roc-auc: 0.979 - roc-auc_val: 0.9766\n",
      "Val ROCs: toxic: 0.9766    severe_toxic: 0.9867    obscene: 0.9872    threat: 0.9652    insult: 0.9799    identity_hate: 0.9641\n",
      "191484/191484 [==============================] - 313s 2ms/step - loss: 0.3002 - toxic_loss: 0.0992 - severe_toxic_loss: 0.0239 - obscene_loss: 0.0610 - threat_loss: 0.0139 - insult_loss: 0.0722 - identity_hate_loss: 0.0300 - val_loss: 0.3418 - val_toxic_loss: 0.1149 - val_severe_toxic_loss: 0.0285 - val_obscene_loss: 0.0737 - val_threat_loss: 0.0124 - val_insult_loss: 0.0801 - val_identity_hate_loss: 0.0322\n",
      "Epoch 8/200\n",
      "191424/191484 [============================>.] - ETA: 0s - loss: 0.2914 - toxic_loss: 0.0956 - severe_toxic_loss: 0.0237 - obscene_loss: 0.0583 - threat_loss: 0.0137 - insult_loss: 0.0703 - identity_hate_loss: 0.0297\n",
      "roc-auc: 0.9806 - roc-auc_val: 0.9755\n",
      "Val ROCs: toxic: 0.9774    severe_toxic: 0.9857    obscene: 0.9881    threat: 0.9638    insult: 0.9812    identity_hate: 0.9568\n",
      "191484/191484 [==============================] - 312s 2ms/step - loss: 0.2914 - toxic_loss: 0.0956 - severe_toxic_loss: 0.0237 - obscene_loss: 0.0583 - threat_loss: 0.0137 - insult_loss: 0.0703 - identity_hate_loss: 0.0297 - val_loss: 0.3100 - val_toxic_loss: 0.1021 - val_severe_toxic_loss: 0.0287 - val_obscene_loss: 0.0587 - val_threat_loss: 0.0132 - val_insult_loss: 0.0746 - val_identity_hate_loss: 0.0326\n",
      "Epoch 9/200\n",
      "191424/191484 [============================>.] - ETA: 0s - loss: 0.2850 - toxic_loss: 0.0929 - severe_toxic_loss: 0.0232 - obscene_loss: 0.0571 - threat_loss: 0.0135 - insult_loss: 0.0690 - identity_hate_loss: 0.0293\n",
      "roc-auc: 0.9816 - roc-auc_val: 0.9771\n",
      "Val ROCs: toxic: 0.9767    severe_toxic: 0.9859    obscene: 0.9886    threat: 0.9673    insult: 0.9823    identity_hate: 0.9618\n",
      "191484/191484 [==============================] - 307s 2ms/step - loss: 0.2850 - toxic_loss: 0.0929 - severe_toxic_loss: 0.0232 - obscene_loss: 0.0571 - threat_loss: 0.0135 - insult_loss: 0.0690 - identity_hate_loss: 0.0293 - val_loss: 0.3255 - val_toxic_loss: 0.1115 - val_severe_toxic_loss: 0.0307 - val_obscene_loss: 0.0649 - val_threat_loss: 0.0128 - val_insult_loss: 0.0748 - val_identity_hate_loss: 0.0309\n",
      "Epoch 10/200\n",
      "191424/191484 [============================>.] - ETA: 0s - loss: 0.2788 - toxic_loss: 0.0906 - severe_toxic_loss: 0.0231 - obscene_loss: 0.0553 - threat_loss: 0.0132 - insult_loss: 0.0680 - identity_hate_loss: 0.0287\n",
      "roc-auc: 0.9668 - roc-auc_val: 0.9577\n",
      "Val ROCs: toxic: 0.8696    severe_toxic: 0.9857    obscene: 0.989    threat: 0.9664    insult: 0.9817    identity_hate: 0.954\n",
      "191484/191484 [==============================] - 307s 2ms/step - loss: 0.2788 - toxic_loss: 0.0906 - severe_toxic_loss: 0.0231 - obscene_loss: 0.0552 - threat_loss: 0.0132 - insult_loss: 0.0680 - identity_hate_loss: 0.0287 - val_loss: 1.2781 - val_toxic_loss: 1.0456 - val_severe_toxic_loss: 0.0380 - val_obscene_loss: 0.0624 - val_threat_loss: 0.0126 - val_insult_loss: 0.0840 - val_identity_hate_loss: 0.0356\n",
      "Epoch 11/200\n",
      "191424/191484 [============================>.] - ETA: 0s - loss: 0.2729 - toxic_loss: 0.0877 - severe_toxic_loss: 0.0231 - obscene_loss: 0.0540 - threat_loss: 0.0132 - insult_loss: 0.0664 - identity_hate_loss: 0.0285\n",
      "roc-auc: 0.9831 - roc-auc_val: 0.9748\n",
      "Val ROCs: toxic: 0.971    severe_toxic: 0.9864    obscene: 0.9874    threat: 0.9705    insult: 0.9787    identity_hate: 0.9548\n",
      "191484/191484 [==============================] - 306s 2ms/step - loss: 0.2730 - toxic_loss: 0.0877 - severe_toxic_loss: 0.0231 - obscene_loss: 0.0540 - threat_loss: 0.0132 - insult_loss: 0.0664 - identity_hate_loss: 0.0285 - val_loss: 0.3589 - val_toxic_loss: 0.1255 - val_severe_toxic_loss: 0.0328 - val_obscene_loss: 0.0705 - val_threat_loss: 0.0120 - val_insult_loss: 0.0844 - val_identity_hate_loss: 0.0337\n",
      "Epoch 12/200\n",
      "191424/191484 [============================>.] - ETA: 0s - loss: 0.2659 - toxic_loss: 0.0844 - severe_toxic_loss: 0.0229 - obscene_loss: 0.0522 - threat_loss: 0.0132 - insult_loss: 0.0653 - identity_hate_loss: 0.0280\n",
      "roc-auc: 0.9845 - roc-auc_val: 0.9725\n",
      "Val ROCs: toxic: 0.9759    severe_toxic: 0.9857    obscene: 0.9874    threat: 0.9516    insult: 0.9824    identity_hate: 0.9523\n",
      "191484/191484 [==============================] - 306s 2ms/step - loss: 0.2659 - toxic_loss: 0.0844 - severe_toxic_loss: 0.0229 - obscene_loss: 0.0522 - threat_loss: 0.0132 - insult_loss: 0.0653 - identity_hate_loss: 0.0280 - val_loss: 0.3375 - val_toxic_loss: 0.1183 - val_severe_toxic_loss: 0.0280 - val_obscene_loss: 0.0690 - val_threat_loss: 0.0125 - val_insult_loss: 0.0776 - val_identity_hate_loss: 0.0322\n",
      "Epoch 13/200\n",
      "191424/191484 [============================>.] - ETA: 0s - loss: 0.2617 - toxic_loss: 0.0833 - severe_toxic_loss: 0.0224 - obscene_loss: 0.0513 - threat_loss: 0.0129 - insult_loss: 0.0638 - identity_hate_loss: 0.0279\n",
      "roc-auc: 0.9806 - roc-auc_val: 0.97\n",
      "Val ROCs: toxic: 0.9683    severe_toxic: 0.956    obscene: 0.9866    threat: 0.9711    insult: 0.98    identity_hate: 0.9583\n",
      "191484/191484 [==============================] - 307s 2ms/step - loss: 0.2616 - toxic_loss: 0.0832 - severe_toxic_loss: 0.0225 - obscene_loss: 0.0513 - threat_loss: 0.0129 - insult_loss: 0.0638 - identity_hate_loss: 0.0279 - val_loss: 0.6935 - val_toxic_loss: 0.1374 - val_severe_toxic_loss: 0.3583 - val_obscene_loss: 0.0720 - val_threat_loss: 0.0118 - val_insult_loss: 0.0822 - val_identity_hate_loss: 0.0318\n",
      "Epoch 14/200\n",
      "191424/191484 [============================>.] - ETA: 0s - loss: 0.2562 - toxic_loss: 0.0805 - severe_toxic_loss: 0.0223 - obscene_loss: 0.0503 - threat_loss: 0.0128 - insult_loss: 0.0626 - identity_hate_loss: 0.0276\n",
      "Epoch 00014: reducing learning rate to 0.00010000000474974513.\n",
      "\n",
      "roc-auc: 0.9839 - roc-auc_val: 0.9749\n",
      "Val ROCs: toxic: 0.974    severe_toxic: 0.9753    obscene: 0.9876    threat: 0.9735    insult: 0.9805    identity_hate: 0.9586\n",
      "191484/191484 [==============================] - 306s 2ms/step - loss: 0.2562 - toxic_loss: 0.0805 - severe_toxic_loss: 0.0223 - obscene_loss: 0.0503 - threat_loss: 0.0128 - insult_loss: 0.0626 - identity_hate_loss: 0.0276 - val_loss: 0.4184 - val_toxic_loss: 0.1307 - val_severe_toxic_loss: 0.0801 - val_obscene_loss: 0.0801 - val_threat_loss: 0.0118 - val_insult_loss: 0.0843 - val_identity_hate_loss: 0.0314\n",
      "Epoch 15/200\n",
      "191424/191484 [============================>.] - ETA: 0s - loss: 0.2360 - toxic_loss: 0.0716 - severe_toxic_loss: 0.0215 - obscene_loss: 0.0454 - threat_loss: 0.0125 - insult_loss: 0.0585 - identity_hate_loss: 0.0264\n",
      "roc-auc: 0.9864 - roc-auc_val: 0.9728\n",
      "Val ROCs: toxic: 0.9739    severe_toxic: 0.9843    obscene: 0.9877    threat: 0.9515    insult: 0.9814    identity_hate: 0.9579\n",
      "191484/191484 [==============================] - 309s 2ms/step - loss: 0.2360 - toxic_loss: 0.0716 - severe_toxic_loss: 0.0215 - obscene_loss: 0.0454 - threat_loss: 0.0125 - insult_loss: 0.0585 - identity_hate_loss: 0.0264 - val_loss: 0.3819 - val_toxic_loss: 0.1326 - val_severe_toxic_loss: 0.0424 - val_obscene_loss: 0.0798 - val_threat_loss: 0.0122 - val_insult_loss: 0.0836 - val_identity_hate_loss: 0.0313\n",
      "Epoch 16/200\n",
      "191424/191484 [============================>.] - ETA: 0s - loss: 0.2302 - toxic_loss: 0.0683 - severe_toxic_loss: 0.0215 - obscene_loss: 0.0441 - threat_loss: 0.0125 - insult_loss: 0.0576 - identity_hate_loss: 0.0262\n",
      "roc-auc: 0.9866 - roc-auc_val: 0.9738\n",
      "Val ROCs: toxic: 0.9711    severe_toxic: 0.9827    obscene: 0.985    threat: 0.9715    insult: 0.9771    identity_hate: 0.9554\n",
      "191484/191484 [==============================] - 312s 2ms/step - loss: 0.2302 - toxic_loss: 0.0683 - severe_toxic_loss: 0.0215 - obscene_loss: 0.0441 - threat_loss: 0.0125 - insult_loss: 0.0576 - identity_hate_loss: 0.0262 - val_loss: 0.3874 - val_toxic_loss: 0.1378 - val_severe_toxic_loss: 0.0375 - val_obscene_loss: 0.0806 - val_threat_loss: 0.0120 - val_insult_loss: 0.0877 - val_identity_hate_loss: 0.0319\n",
      "Epoch 17/200\n",
      "191424/191484 [============================>.] - ETA: 0s - loss: 0.2270 - toxic_loss: 0.0670 - severe_toxic_loss: 0.0211 - obscene_loss: 0.0434 - threat_loss: 0.0125 - insult_loss: 0.0571 - identity_hate_loss: 0.0259\n",
      "roc-auc: 0.9867 - roc-auc_val: 0.9725\n",
      "Val ROCs: toxic: 0.9677    severe_toxic: 0.9847    obscene: 0.9843    threat: 0.9718    insult: 0.9745    identity_hate: 0.9519\n",
      "191484/191484 [==============================] - 307s 2ms/step - loss: 0.2270 - toxic_loss: 0.0670 - severe_toxic_loss: 0.0211 - obscene_loss: 0.0434 - threat_loss: 0.0125 - insult_loss: 0.0571 - identity_hate_loss: 0.0259 - val_loss: 0.3986 - val_toxic_loss: 0.1448 - val_severe_toxic_loss: 0.0342 - val_obscene_loss: 0.0836 - val_threat_loss: 0.0119 - val_insult_loss: 0.0918 - val_identity_hate_loss: 0.0323\n",
      "Epoch 18/200\n",
      "191424/191484 [============================>.] - ETA: 0s - loss: 0.2244 - toxic_loss: 0.0656 - severe_toxic_loss: 0.0211 - obscene_loss: 0.0427 - threat_loss: 0.0123 - insult_loss: 0.0566 - identity_hate_loss: 0.0261\n",
      "roc-auc: 0.987 - roc-auc_val: 0.9717\n",
      "Val ROCs: toxic: 0.9653    severe_toxic: 0.984    obscene: 0.9839    threat: 0.9727    insult: 0.9738    identity_hate: 0.9502\n",
      "191484/191484 [==============================] - 307s 2ms/step - loss: 0.2244 - toxic_loss: 0.0656 - severe_toxic_loss: 0.0211 - obscene_loss: 0.0427 - threat_loss: 0.0123 - insult_loss: 0.0566 - identity_hate_loss: 0.0261 - val_loss: 0.3991 - val_toxic_loss: 0.1498 - val_severe_toxic_loss: 0.0349 - val_obscene_loss: 0.0795 - val_threat_loss: 0.0117 - val_insult_loss: 0.0909 - val_identity_hate_loss: 0.0321\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fc93c82c4e0>"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K.set_value(model.optimizer.lr, 1e-3)\n",
    "model.fit(x = dataInputTrain, \n",
    "          y = [traindf[i] for i in output_names],\n",
    "         batch_size = 64, epochs = 200, validation_data = [dataInputVal, [valdf[i] for i in output_names]],\n",
    "         callbacks=[earlyStopping, mcp_save, reduce_lr_loss, tensor_board, roc_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examining what the model got wrong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_val = model.predict(dataInputVal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for count,i in enumerate(output_names):\n",
    "#     print('---------------' + i + '---------------------')\n",
    "#     dif = (valdf[i] - pred_val[count].flatten()).abs().sort_values(ascending = False)\n",
    "#     most_dif = valdf.loc[dif.index[:2]]\n",
    "#     for count2, j in enumerate(most_dif.iterrows()):\n",
    "#         print('Predicted', pred_val[count].flatten()[valdf[i].index.get_loc(j[0])]\n",
    "#               , 'Actual', j[1][i],\n",
    "#              '\\n',\n",
    "#              j[1]['comment_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred = model.predict(test_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for count,i in enumerate(output_names):\n",
    "    test[i] = pred[count].flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test[['id', 'toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']].to_csv('data/answers/cnn1.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_stopped = load_model('weights/cnn_mdl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_stopped = model_stopped.predict(test_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for count,i in enumerate(output_names):\n",
    "    test[i] = pred[count].flatten()\n",
    "test[['id', 'toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']].to_csv('data/answers/cnnStopped.csv', index = False)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
