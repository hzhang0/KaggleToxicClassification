{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = os.listdir('data/answers')\n",
    "output_names = ['toxic','severe_toxic','obscene','threat','insult','identity_hate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['linear_ensemble_0.75_09723.csv',\n",
       " 'lstm_09832.csv',\n",
       " 'linear_ensemble_0.9_09724.csv',\n",
       " 'linear_baseline1_09717.csv',\n",
       " 'linear_ensemble_0.8_09723.csv',\n",
       " 'lstm2_09831.csv',\n",
       " 'linear_ensemble_0.5_09713.csv',\n",
       " 'linear_baseline2_09600.csv',\n",
       " 'linear_ensemble_0.85_09724.csv',\n",
       " 'lstm_09831.csv',\n",
       " 'lstm_09843.csv',\n",
       " 'lstm_09844.csv',\n",
       " 'gru_09811.csv',\n",
       " 'gru_09837.csv',\n",
       " 'gru_09835.csv',\n",
       " 'lstm_09838.csv',\n",
       " 'lstm_09828.csv',\n",
       " 'gru_09845.csv']"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "def blend(outName = '' , filtering = ['lstm', 'gru'], topn = None, weighted = False, weightedMin=0.95, ):\n",
    "    '''\n",
    "    Inputs:\n",
    "        outName: output file name\n",
    "        filtering: list of regular expressions\n",
    "        topn: int or None. whether or not to take n scores after regex matching\n",
    "        weighted: whether to use a simple average or a weighted average\n",
    "        weightedMin: score to subtract all scores from before scaling sums of scores to one        \n",
    "    '''\n",
    "    answer = pd.DataFrame(columns = ['id'] + output_names)\n",
    "    filesToRead = []\n",
    "    for i in files:\n",
    "        if any([re.search(j, i) for j in filtering]):\n",
    "            filesToRead.append(i)\n",
    "    scores = {}\n",
    "    for i in filesToRead:\n",
    "        scores[i] = float('0.' + re.findall(r'_([0-9]+)\\.csv',i)[0][1:])\n",
    "    if topn:\n",
    "        toTake = list(zip(*sorted(scores.items(), key = lambda x: -x[1])[:topn]))[0]\n",
    "    else:\n",
    "        toTake = filesToRead\n",
    "        \n",
    "    preds = {}       \n",
    "    for i in toTake:\n",
    "        preds[i] = pd.read_csv('data/answers/' + i)\n",
    "        preds[i] = preds[i].sort_values(by = 'id')    \n",
    "    answer['id'] = preds[i]['id']\n",
    "    results = np.zeros(shape = (preds[i].shape[0], preds[i].shape[1] - 1, len(toTake)))\n",
    "    for c, i in enumerate(preds):\n",
    "        results[:,:,c] = preds[i][output_names].values\n",
    "        \n",
    "    if not weighted:\n",
    "        answer[output_names] = np.mean(results, axis = -1)\n",
    "    else:\n",
    "        assert(all([scores[i]-weightedMin >= 0 for i in toTake]))\n",
    "        total = sum([scores[i] - weightedMin for i in toTake])\n",
    "        scalings = [(scores[i] - weightedMin)/total for i in toTake]\n",
    "        for i in range(len(toTake)):\n",
    "            results[:,:,i] *= scalings[i]            \n",
    "        answer[output_names] = np.sum(results, axis = -1)\n",
    "    answer.to_csv('data/answers/ensembles/'+outName, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "blend('allUnweighted.csv', filtering = ['.*'])\n",
    "blend('allWeighted095.csv', filtering = ['.*'], weighted = True, weightedMin=0.95)\n",
    "blend('allWeighted096.csv', filtering = ['.*'], weighted = True, weightedMin=0.96)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(3, 12,2): #unweighted GRUs and LSTMs\n",
    "    blend('unweightedRNNTop'+str(i) + '.csv', topn= i )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(3, 12,2): #weighted GRUs and LSTMs\n",
    "    blend('weightedRNN098Top'+str(i) + '.csv', topn= i, weighted = True, weightedMin= 0.98)\n",
    "    blend('weightedRNN097Top'+str(i) + '.csv', topn= i, weighted = True, weightedMin= 0.97)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
